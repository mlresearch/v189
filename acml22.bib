@Proceedings{ACML-2022,
  booktitle =	 {Proceedings of The 14th Asian Conference on Machine
                  Learning},
  name =	 {Asian Conference on Machine Learning},
  shortname =	 {ACML},
  sections =	 {Preface|Contributed Papers},
  editor =	 {Vineeth N Balasubramanian and Ivor Tsang},
  volume =	 189,
  year =	 2022,
  start =	 {2022-12-12},
  end =		 {2022-12-14},
  published =	 {2023-04-13},
  conference_url ={https://www.acml-conf.org/2022/},
  address =	 {Hyderabad, India}
}

@InProceedings{liu22,
  title =	 {FF-Net: An End-to-end Feature-Fusion Network for
                  Double JPEG Detection and Localization},
  author =	 {Liu, Bo and Wu, Ranglei and Bi, Xiuli and Xiao, Bin},
  pages =	 {643-657},
  crossref =	 {acml22},
  abstract =	 {In the real-world, most images are saved in JPEG
                  format, so many forged images are partially or
                  totally composed of JPEG images and then saved in
                  JPEG format again. In this case, exposing forged
                  images can be accomplished by the detection of
                  double JPEG compressions. Although the detection
                  methods of double JPEG compressions have greatly
                  improved, they rely on handcrafted features of image
                  patches and cannot locate forgery at pixel-level. To
                  break this limitation, we propose an end-to-end
                  feature-fusion network (FF-Net) for double
                  compression detection and forgery localization. We
                  find that JPEG compression fingerprint primarily
                  exists on the high-frequency component of an image,
                  and the singly and doubly compression yield
                  different fingerprints. Therefore, we design two
                  encoders cooperatively to learn the compression
                  fingerprint directly from the whole image. A decoder
                  is deployed to locate the regions with different
                  compression fingerprints at pixel-level based on the
                  learned compression fingerprint. The experiment
                  results verify that the proposed FF-Net can detect
                  and locate the forged regions more accurately than
                  these existing detection methods. Besides, it has a
                  good generalization ability that the network trained
                  on one compression case can work in numerous
                  compression cases. Moreover, it can detect different
                  local forgeries, including copy-move, splicing, and
                  object-removal.}
}

@InProceedings{zhao22,
  title =	 {Constrained Density Matching and Modeling for
                  Cross-lingual Alignment of Contextualized
                  Representations},
  author =	 {Zhao, Wei and Eger, Steffen},
  pages =	 {1245-1260},
  crossref =	 {acml22},
  abstract =	 {Multilingual representations pre-trained with
                  monolingual data exhibit considerably unequal task
                  performances across languages. Previous studies
                  address this challenge with resource-intensive
                  contextualized alignment, which assumes the
                  availability of large parallel data, thereby leaving
                  under-represented language communities behind. In
                  this work, we attribute the data hungriness of
                  previous alignment techniques to two limitations:
                  (i) the inability to sufficiently leverage data and
                  (ii) these techniques are not trained properly. To
                  address these issues, we introduce supervised and
                  unsupervised density-based approaches named Real-NVP
                  and GAN-Real-NVP, driven by Normalizing Flow, to
                  perform alignment, both dissecting the alignment of
                  multilingual subspaces into density matching and
                  density modeling. We complement these approaches
                  with our validation criteria in order to guide the
                  training process. Our experiments encompass 16
                  alignments, including our approaches, evaluated
                  across 6 language pairs, synthetic data and 5 NLP
                  tasks. We demonstrate the effectiveness of our
                  approaches in the scenarios of limited and no
                  parallel data. First, our supervised approach
                  trained on 20k parallel data (sentences) mostly
                  surpasses Joint-Align and InfoXLM trained on over
                  100k parallel sentences. Second, parallel data can
                  be removed without sacrificing performance when
                  integrating our unsupervised approach in our
                  bootstrapping procedure, which is theoretically
                  motivated to enforce equality of multilingual
                  subspaces. Moreover, we demonstrate the advantages
                  of validation criteria over validation data for
                  guiding supervised training.}
}

@InProceedings{liao22,
  title =	 {Locally Differentially Private Reinforcement
                  Learning for Linear Mixture Markov Decision
                  Processes},
  author =	 {Liao, Chonghua and He, Jiafan and Gu, Quanquan},
  pages =	 {627-642},
  crossref =	 {acml22},
  abstract =	 {Reinforcement learning (RL) algorithms can be used
                  to provide personalized services, which rely on
                  users' private and sensitive data. To protect the
                  users' privacy, privacy-preserving RL algorithms are
                  in demand. In this paper, we study RL with linear
                  function approximation and local differential
                  privacy (LDP) guarantees. We propose a novel
                  $(\varepsilon, \delta)$-LDP algorithm for learning a
                  class of Markov decision processes (MDPs) dubbed
                  linear mixture MDPs, and obtains an
                  $\tilde{\mathcal{O}}(
                  d^{5/4}H^{7/4}T^{3/4}\left(\log(1/\delta)\right)^{1/4}\sqrt{1/\varepsilon})$
                  regret, where $d$ is the dimension of feature
                  mapping, $H$ is the length of the planning horizon,
                  and $T$ is the number of interactions with the
                  environment.  We also prove a lower bound
                  $\Omega(dH\sqrt{T}/\left(e^{\varepsilon}(e^{\varepsilon}-1)\right))$
                  for learning linear mixture MDPs under
                  $\varepsilon$-LDP constraint. Experiments on
                  synthetic datasets verify the effectiveness of our
                  algorithm. To the best of our knowledge, this is the
                  first provable privacy-preserving RL algorithm with
                  linear function approximation.}
}

@InProceedings{ghiassi22-1,
  title =	 {Trusted Loss Correction for Noisy Multi-Label
                  Learning},
  author =	 {Ghiassi, Amirmasoud and Pene, Cosmin Octavian and
                  Birke, Robert and Chen, Lydia.Y},
  pages =	 {343-358},
  crossref =	 {acml22},
  abstract =	 {Noisy and corrupted labels are shown to
                  significantly undermine the performance of
                  multi-label learning, which has multiple labels in
                  each image. Correcting the loss via a label
                  corruption matrix is effective in improving the
                  robustness of single-label classification against
                  noisy labels. However, estimating the corruption
                  matrix for multi-label problems is no mean feat due
                  to the unbalanced distributions of labels and the
                  presence of multiple objects that may be mapped into
                  the same labels. In this paper, we propose a robust
                  multi-label classifier against label noise, TLCM,
                  which corrects the loss based on a corruption matrix
                  estimated on trusted data. To overcome the challenge
                  of unbalanced label distribution and multi-object
                  mapping, we use trusted single-label data as
                  regulators to correct the multi-label corruption
                  matrix. Empirical evaluation on real-world vision
                  and object detection datasets, i.e., MS-COCO,
                  NUS-WIDE, and MIRFLICKR, shows that our method under
                  medium (30%) and high (60%) corruption levels
                  outperforms state-of-the-art multi-label classifier
                  (ASL) and noise-resilient multi-label classifier
                  (MPVAE), by on average 12.5% and 26.3% mean average
                  precision (mAP) points, respectively.}
}﻿

@InProceedings{nayman22,
  title =	 {BINAS: Bilinear Interpretable Neural Architecture
                  Search},
  author =	 {Nayman, Niv and Aflalo, Yonathan and Noy, Asaf and
                  Zelnik-Manor, Lihi},
  pages =	 {786-801},
  crossref =	 {acml22},
  abstract =	 {Realistic use of neural networks often requires
                  adhering to multiple constraints on latency, energy
                  and memory among others.  A popular approach to find
                  fitting networks is through constrained Neural
                  Architecture Search (NAS). However, previous methods
                  use complicated predictors for the accuracy of the
                  network.  Those predictors are hard to interpret and
                  sensitive to many hyperparameters to be tuned,
                  hence, the resulting accuracy of the generated
                  models is often harmed.  In this work we resolve
                  this by introducing Bilinear Interpretable Neural
                  Architecture Search (BINAS), that is based on an
                  accurate and simple bilinear formulation of both an
                  accuracy estimator and the expected resource
                  requirement, together with a scalable search method
                  with theoretical guarantees. The simplicity of our
                  proposed estimator together with the intuitive way
                  it is constructed bring interpretability through
                  many insights about the contribution of different
                  design choices. For example, we find that in the
                  examined search space, adding depth and width is
                  more effective at deeper stages of the network and
                  at the beginning of each resolution stage.  Our
                  experiments show that BINAS generates comparable to
                  or better architectures than other state-of-the-art
                  NAS methods within a reduced search cost for each
                  additional generated network, while strictly
                  satisfying the resource constraints.}
}

@InProceedings{alami22,
  title =	 {Bayesian Change-Point Detection for Bandit Feedback
                  in Non-stationary Environments},
  author =	 {Alami, Reda},
  pages =	 {17-31},
  crossref =	 {acml22},
  abstract =	 {The stochastic multi-armed bandit problem has been
                  widely studied under the stationary
                  assumption. However in real world problems and
                  industrial applications, this assumption is often
                  unrealistic because the distributions of rewards may
                  change over time. In this paper, we consider the
                  piece-wise iid non-stationary stochastic multi-armed
                  bandit problem with unknown change-points and we
                  focus on the change of mean setup. To solve the
                  latter, we propose a change-point based framework
                  where we study a class of change-detection based
                  optimal bandit policies that actively detects
                  change-point using the restarted Bayesian online
                  change-point detector and then restarts the bandit
                  indices. Analytically, in the context of regret
                  minimization, our proposal achieves a
                  $\mathcal{O}(\sqrt{A T K_T })$ regret upper-bound
                  where $K_T$ is the overall number of change-points
                  up to the horizon $T$ and $A$ is the number of
                  arms. The derived bound matches the existing lower
                  bound for abruptly changing environments. Finally,
                  we demonstrate the cumulative regret reduction of
                  the our proposal over synthetic Bernoulli rewards as
                  well as Yahoo! datasets of webpage click-through
                  rates.}
}

@InProceedings{sundaray22,
  title =	 {Auto-Physics-Encoder: Using Physics-Informed Latent
                  Layer Two-Way Physics Flow for Monitoring Systems
                  with Unobservability},
  author =	 {Sundaray, Priyabrata and Weng, Yang},
  pages =	 {958-973},
  crossref =	 {acml22},
  abstract =	 {With the Internet of Everything (IoE) nowadays,
                  monitoring edge systems is essential for
                  coordinating everything into an IoE web. However, it
                  is hard to monitor edge systems due to limited
                  system information and limited sensors. To infer
                  system information and provide robust monitoring
                  capability, machine learning models were used to
                  approximate mapping rules between different
                  measurements. However, mapping rule learning using
                  traditional machine learning tools is one way only,
                  e.g., from measurement variables to the state vector
                  variables. And, it is hard to be reverted, leading
                  to over-fitting because of inconsistency between the
                  forward and inverse learnings. Hence, we propose a
                  structural deep neural network framework to provide
                  a coherent two-way functional approximation. For
                  physical regularization, we embed network size into
                  the number of variables in the latent layers. We
                  also utilize state sensors in the `latent layer' to
                  guide other latent variables to create state
                  sets. The performance of reconstruction for the
                  two-way mapping rule is validated extensively using
                  test cases in the engineering, physics, and
                  mathematical analysis domain.}
}

@InProceedings{lu22-2,
  title =	 {Multi-Scale Anomaly Detection for Time Series with
                  Attention-based Recurrent Autoencoders},
  author =	 {Qingning, Lu and Wenzhong, Li and Chuanze, Zhu and
                  Yizhou, Chen and Yinke, Wang and Zhijie, Zhang and
                  Linshan, Shen and Sanglu, Lu},
  pages =	 {674-689},
  crossref =	 {acml22},
  abstract =	 {Anomaly detection on time series is an important
                  research topic in data mining, which has a wide
                  range of applications in financial markets,
                  biological data, information technology,
                  manufacturing system, etc. However, the existing
                  time series anomaly detection methods mainly capture
                  temporal features from a single-scale viewpoint,
                  which cannot detect multi-scale anomalies
                  effectively. In this paper, we propose a novel
                  approach of Multi-scale Anomaly Detection for Time
                  Series (MAD-TS) with an attention-based recurrent
                  autoencoder model to solve the above problem. The
                  proposed method adopts a hierarchically connected
                  recurrent encoder to extract the features of a time
                  series from different levels. The multi-scale
                  features are then fused by a hierarchical decoder
                  with attention mechanism to reconstruct the original
                  sequence at different scales. Based on the
                  reconstruction errors at multiple scales, anomaly
                  scores can be learned for different data points,
                  which can be used to infer the anomaly status of the
                  time series. Extensive experiments based on five
                  open time series datasets show that the proposed
                  MAD-TS method achieves significant performance
                  improvement on anomaly detection compared to the
                  state-of-the-arts.}
}

@InProceedings{chen22-1,
  title =	 {Balanced Spatial-Temporal Graph Structure Learning
                  for Multivariate Time Series Forecasting: A
                  Trade-off between Efficiency and Flexibility},
  author =	 {Chen, Weijun and Wang, Yanze and Du, Chengshuo and
                  Jia, Zhenglong and Liu, Feng and Chen, Ran},
  pages =	 {185-200},
  crossref =	 {acml22},
  abstract =	 {Accurate forecasting of multivariate time series is
                  an extensively studied subject in finance,
                  transportation, and computer science. Fully mining
                  the correlation and causation between the variables
                  in a multivariate time series exhibits noticeable
                  results in improving the performance of a time
                  series model. Recently, some models have explored
                  the dependencies between variables through
                  end-to-end graph structure learning without the need
                  for predefined graphs. However, current models do
                  not incorporate the trade-off between efficiency and
                  flexibility and make insufficient use of the
                  information contained in time series in the design
                  of graph structure learning algorithms. This paper
                  alleviates the above issues by proposing Balanced
                  Graph Structure Learning for Forecasting (BGSLF), a
                  novel and effective deep learning model that joins
                  graph structure learning and
                  forecasting. Technically, BGSLF leverages the
                  spatial information into convolutional operations
                  and extracts temporal dynamics using the diffusion
                  convolutional recurrent network. The proposed
                  framework emphasizes the trade-off between
                  efficiency and flexibility by introducing
                  Multi-Graph Generation Network (MGN) and Graph
                  Selection Module. In addition, a method named Smooth
                  Sparse Unit (SSU) is designed to sparse the learned
                  graph structures, which conforms to the sparse
                  spatial correlations in the real world. Extensive
                  experiments on four real-world datasets demonstrate
                  that our model achieves state-of-the-art
                  performances with minor trainable parameters. Our
                  code is publicly available at
                  https://github.com/onceCWJ/BGSLF.}
}

@InProceedings{ghiassi22-2,
  title =	 {Multi Label Loss Correction against Missing and
                  Corrupted Labels},
  author =	 {Ghiassi, Amirmasoud and Birke, Robert and Chen,
                  Lydia.Y},
  pages =	 {359-374},
  crossref =	 {acml22},
  abstract =	 {Missing and corrupted labels can significantly ruin
                  the learning process and, consequently, the
                  classifier performance. Multi-label learning where
                  each instance is tagged with variable number of
                  labels is particularly affected. Although missing
                  labels (false-negatives) is a well-studied problem
                  in multi-label learning, it is considerably more
                  challenging to have both false-negatives (missing
                  labels) and false-positives (corrupted labels)
                  simultaneously in multi-label datasets. In this
                  paper, we propose Multi-Label Loss with Self
                  Correction (MLLSC) which is a loss robust against
                  coincident missing and corrupted labels. MLLSC
                  computes the loss based on the true-positive
                  (true-negative) or false-positive (false-negative)
                  labels and deep neural network expertise. To
                  distinguish between false-positive (false-negative)
                  and true-positive (true-negative) labels, we use the
                  output probability of the deep neural network during
                  the learning process. Our method As MLLSC can be
                  combined with different types of multi-label loss
                  functions, we also address the label imbalance
                  problem of multi-label datasets. Empirical
                  evaluation on real-world vision datasets, i.e.,
                  MS-COCO, and MIR-FLICKR, shows that our method under
                  medium (0.3) and high (0.6) corrupted and missing
                  label probabilities outperform the state-of-the-art
                  methods by, on average 23.97% and 9.31% mean average
                  precision (mAP) points, respectively.}
}

@InProceedings{sun22,
  title =	 {Feature Distribution Matching for Federated Domain
                  Generalization},
  author =	 {Sun, Yuwei and Chong, Ng and Ochiai, Hideya},
  pages =	 {942-957},
  crossref =	 {acml22},
  abstract =	 {Multi-source domain adaptation has been intensively
                  studied. The distribution shift in features inherent
                  to specific domains causes the negative transfer
                  problem, degrading a model’s generality to unseen
                  tasks. In Federated Learning (FL), learned model
                  parameters are shared to train a global model that
                  leverages the underlying knowledge across client
                  models trained on separate data
                  domains. Nonetheless, the data confidentiality of FL
                  hinders the effectiveness of traditional domain
                  adaptation methods that require prior knowledge of
                  different domain data. We propose a new federated
                  domain generalization method called Federated
                  Knowledge Alignment (FedKA). FedKA leverages feature
                  distribution matching in a global workspace such
                  that the global model can learn domain-invariant
                  client features under the constraint of unknown
                  client data. FedKA employs a federated voting
                  mechanism that generates target domain pseudo-labels
                  based on the consensus from clients to facilitate
                  global model fine-tuning. We performed extensive
                  experiments, including an ablation study, to
                  evaluate the effectiveness of the proposed method in
                  both image and text classification tasks using
                  different model architectures. The empirical results
                  show that FedKA achieves performance gains of 8.8\%
                  and 3.5\% in Digit-Five and Office-Caltech10,
                  respectively, and a gain of 0.7\% in Amazon Review
                  with extremely limited training data. Moreover, we
                  studied the effectiveness of FedKA in alleviating
                  the negative transfer of FL based on a new criterion
                  called Group Effect. The results show that FedKA can
                  reduce negative transfer, improving the performance
                  gain via model aggregation by 4 times.}
}

@InProceedings{li22-2,
  title =	 {Contrastive Inductive Bias Controlling Networks for
                  Reinforcement Learning},
  author =	 {Li, Dongxu and Wang, Shaochen and Chen, Kang and Li,
                  Bin},
  pages =	 {563-578},
  crossref =	 {acml22},
  abstract =	 {Effective learning in an visual-based environment is
                  essential for reinforcement learning (RL) agent,
                  while it has been empirically observed that learning
                  from high dimensional observations such as raw
                  pixels is sample-inefficient. For common practice,
                  RL algorithms for image input often use encoders
                  composed of CNNs to extract useful features from
                  high dimensional observations. Recent studies have
                  shown that CNNs have strong inductive bias towards
                  image styles rather than content (i.e. agent
                  shapes), while content is the information that RL
                  algorithms should focus on. Inspired by this, we
                  suggest reducing the intrinsic style bias of CNNs by
                  proposing Contrastive Inductive Bias Controlling
                  Networks for RL. It can help RL algorithms
                  effectively focus on truly noteworthy information
                  like agents' own characteristics. Our approach
                  incorporates two transfer networks and feature
                  encoder with contrastive learning methods, guiding
                  RL algorithms to learn more efficiently with
                  sampling. Extensive experiments show that the
                  extended framework greatly enhances the performance
                  of existing model-free methods (i.e. SAC), enabling
                  it to reach state-of-the-art performance on the
                  DeepMind control suite benchmark.}
}

@InProceedings{cao22,
  title =	 {Robust Scene Text Detection via Learnable Scene
                  Transformations},
  author =	 {Cao, Yuheng and Zhou, Mengjie and Chen, Jie},
  pages =	 {137-152},
  crossref =	 {acml22},
  abstract =	 {Scene text detection based on deep neural networks
                  has been extensively studied in the last few
                  years. However, the task of detecting texts in
                  complex scenes such as bad weather and image
                  distortions has not received sufficient attentions
                  in existing works, which is crucial for real-world
                  applications such as text translation, autonomous
                  driving, etc. In this paper, we propose a novel
                  strategy to automatically search for the effective
                  scene transformation polices to augment images in
                  the training phase. In addition, we build a new
                  dataset, Robust-Text, to evaluate the robustness of
                  text detection methods in real complex
                  scenes. Experiments conducted on the ICDAR2015,
                  MSRA-TD500 and Robust-Text datasets demonstrate that
                  our method can effectively improve the robustness of
                  text detectors in complex scenes.}
}

@InProceedings{yuan22,
  title =	 {Learning with Interactive Models over
                  Decision-Dependent Distributions},
  author =	 {Yuan, Man-Jie and Gao, Wei},
  pages =	 {1229-1244},
  crossref =	 {acml22},
  abstract =	 {Classical supervised learning generally trains one
                  model from an i.i.d. data according to an unknown
                  yet fixed distribution. In some real applications
                  such as finance, however, multiple models may be
                  trained by different companies and interacted in a
                  dynamic environment, where the data distribution may
                  take shift according to different models'
                  decisions. In this work, we study two models for
                  simplicity, and formalize such scenario as a
                  learning problem of two models over
                  decision-dependent distributions. We develop the
                  Repeated Risk Minimization (RRM) for two models, and
                  present a sufficient condition to the existence of
                  stable points for RRM, that is, an equilibrium
                  notion. We further provide the theoretical analysis
                  for the convergence of RRM to stable points based on
                  data distribution and finite training sample,
                  respectively. We also study more practical
                  algorithms, such as gradient descent and stochastic
                  gradient descent, to solve the RRM problem with
                  convergence guarantees and we finally present some
                  empirical studies to validate our theoretical
                  analysis.}
}

@InProceedings{li22-1,
  title =	 {Probabilistic Adaptive Spatial-Temporal Regularized
                  Correlation Filters for UAV Tracking},
  author =	 {Li, Rui and Li, Xiao},
  pages =	 {547-562},
  crossref =	 {acml22},
  abstract =	 {Most existing trackers based on spatial-temporal
                  regularized correlation filters exploit response map
                  variation to adapt regularization terms to object
                  appearance changes automatically. However, these
                  trackers ignore the high uncertainty of the response
                  map when the object is occluded or similar objects
                  around, making them unable to learn reliable filters
                  accurately. Furthermore, most correlation filters
                  use linear interpolation directly to update the
                  filter model at each frame, which may cause model
                  degradation once the tracking result is inaccurate
                  or missing. In this work, we propose a novel
                  probabilistic adaptive spatial-temporal regularized
                  correlation filters (PASTRCF) to solve the two
                  issues mentioned above. A probabilistic model
                  constructing the reliability of the response map is
                  introduced to accurately utilize the information in
                  the response map to learn regularization
                  coefficients adaptively. The adaptive threshold
                  mechanism provides an appropriate strategy to update
                  the filter model to alleviate model
                  degradation. Extensive experiments on UAV benchmarks
                  have proven the favorable performance of our method
                  compared to the state-of-art trackers, with robust
                  tracking while ensuring real-time performance.}
}

@InProceedings{su22,
  title =	 {On PAC Learning Halfspaces in Non-interactive Local
                  Privacy Model with Public Unlabeled Data},
  author =	 {Su, Jinyan and Xu, Jinhui and Wang, Di},
  pages =	 {927-941},
  crossref =	 {acml22},
  abstract =	 {In this paper, we study the problem of PAC learning
                  halfspaces in the non-interactive local differential
                  privacy model (NLDP).  To breach the barrier of
                  exponential sample complexity, previous results
                  studied a relaxed setting where the server has
                  access to some additional public but unlabeled
                  data. We continue in this direction. Specifically,
                  we consider the problem under the standard setting
                  instead of the large margin setting studied
                  before. Under different mild assumptions on the
                  underlying data distribution, we propose two
                  approaches that are based on the Massart noise model
                  and self-supervised learning and show that it is
                  possible to achieve sample complexities that are
                  only linear in the dimension and polynomial in other
                  terms for both private and public data, which
                  significantly improve the previous results. Our
                  methods could also be used for other private PAC
                  learning problems.}
}

@InProceedings{chang22,
  title =	 {A two-stream convolution architecture for ESC based
                  on audio feature distanglement},
  author =	 {Zhenghao Chang and Ruhan He and Yongsheng Yu and
                  Zili Zhang and GeLi Bai},
  pages =	 {153-168},
  crossref =	 {acml22},
  abstract =	 { ESC (Environmental Sound Classification) is an
                  active area of research in the field of audio
                  classification that has made significant progress in
                  recent years. The current mainstream ESC methods are
                  based on increasing the dimension of the extracted
                  audio features and therefore draw on the
                  two-dimensional convolution methods used in image
                  processing. However, two-dimensional convolution is
                  expensive to train and the complexity of the
                  corresponding model is usually very high. In
                  response to these issues, we propose a novel
                  two-stream neural network model by the idea of
                  disentanglement, which uses onedimensional
                  convolution for feature extraction to disentangle
                  the audio features into the time and frequency
                  domains separately. Our approach balances
                  computational pressure with classification accuracy
                  well. The accuracy of our approach on the Urbansound
                  8k and Esc-10 datasets was 98.51\% and 97.50\%,
                  respectively, which exceeds that of most
                  models. Meanwhile, the model complexity is also
                  lower.}
}

@InProceedings{xu22,
        title = {An Enhanced Human Activity Recognition Algorithm with Positional Attention},
        author = {Chenyang Xu and Jianfei Shen and Feiyi Fan and Tian Qiu and Zhihong Mao},
        pages = {1181-1196},
        crossref = {acml22},
        abstract = {Human activity recognition (HAR) attracts widespread attention from researchers recently, and deep learning is employed as a dominant paradigm of solving HAR problems. The previous techniques rely on domain knowledge or attention mechanism extract long-range dependency in temporal dimension and cross channel correlation in sensor's channel dimension. In this paper, a HAR model with positional attention (PA), termed as PA-HAR, is presented. To enhance the features in both sensor's channel and temporal dimensions, we propose to split the sensor signals into two 1D features to capture the long-range dependency along the temporal-axis and signal's cross-channel information along the sensor's channel-axis. Furthermore, we embed the features with positional information by encoding the generated features into pairs of temporal-aware and sensor's channel-aware attention maps and weighting the input feature maps. Extensive experiments based on five public datasets demonstrate that the proposed PA-HAR algorithm achieves a competitive performance in HAR related tasks compared with the state-of-the-art approaches.}
}

@InProceedings{pote22,
  title =	 {Dynamic Forward and Backward Sparse Training
                  (DFBST): Accelerated Deep Learning through
                  Completely Sparse Training Schedule},
  author =	 {Pote,Tejas and Ganaie,Muhammad Athar and Hassan,Atif
                  and Khare,Swanand},
  pages =	 {848-863},
  crossref =	 {acml22},
  abstract =	 {Neural network sparsification has received a lot of
                  attention in recent years. A number of dynamic
                  sparse training methods have been developed that
                  achieve significant sparsity levels during training,
                  ensuring comparable performance to their dense
                  counterparts. However, most of these methods update
                  all the model parameters using dense gradients. To
                  this end, gradient sparsification is achieved either
                  by non-dynamic (fixed) schedule or computationally
                  expensive dynamic pruning schedule. To alleviate
                  these drawbacks, we propose Dynamic Forward and
                  Backward Sparse Training (DFBST), an algorithm which
                  dynamically sparsifies both the forward and backward
                  passes using trainable masks, leading to a
                  completely sparse training schedule. In contrast to
                  existing sparse training methods, we propose
                  separate learning for forward as well as backward
                  masks. Our approach achieves state of the art
                  performance in terms of both accuracy and sparsity
                  compared to existing dynamic pruning algorithms on
                  benchmark datasets, namely MNIST, CIFAR-10 and
                  CIFAR-100.}
}

@InProceedings{bhosale22,
  title =	 {Learning with Domain Knowledge to Develop
                  Justifiable Convolutional Networks},
  author =	 {Bhosale, Rimmon and Das, Mrinal},
  pages =	 {64-79},
  crossref =	 {acml22},
  abstract =	 {The inherent structure of the Convolutional Neural
                  Networks (CNN) allows them to extract features that
                  are highly correlated with the classes while
                  performing image classification. However, it may
                  happen that the extracted features are merely
                  coincidental and may not be justifiable from a human
                  perspective. For example, from a set of images of
                  cows on grassland, CNN can erroneously extract grass
                  as the feature of the class cow. There are two main
                  limitations to this kind of learning: firstly, in
                  many false-negative cases, correct features will not
                  be used, and secondly, in false-positive cases the
                  system will lack accountability. There is no
                  implicit way to inform CNN to learn the features
                  that are justifiable from a human perspective to
                  resolve these issues. In this paper, we argue that
                  if we provide domain knowledge to guide the learning
                  process of CNN, it is possible to reliably learn the
                  justifiable features. We propose a systematic yet
                  simple mechanism to incorporate domain knowledge to
                  guide the learning process of the CNNs to extract
                  justifiable features. The flip side is that it needs
                  additional input. However, we have shown that even
                  with minimal additional input our method can
                  effectively propagate the knowledge within a class
                  during training. We demonstrate that justifiable
                  features not only enhance accuracy but also demand
                  less amount of data and training time. Moreover, we
                  also show that the proposed method is more robust
                  against perturbational changes in the input images.}
}

@InProceedings{deng22-2,
  title =	 {A Self-improving Skin Lesions Diagnosis Framework
                  Via Pseudo-labeling and Self-distillation},
  author =	 {Deng, Shaochang and Yin, Mengxiao and Yang,Feng},
  pages =	 {296-310},
  crossref =	 {acml22},
  abstract =	 {In the past few years, supervised-based deep
                  learning methods has yielded good results in skin
                  lesions diagnosis tasks. Unfortunately, obtaining
                  large of labels for medical images is expensive and
                  time consuming. In this paper, we propose a
                  self-improving skin lesions diagnosis (SISLD)
                  framework to explore useful information in unlabeled
                  data. We first propose a semi-supervised model
                  ${f}$, which combining consistency and
                  class-balanced pseudo-labeling to make full use of
                  unlabeled data in scenarios with sparse manually
                  labeled samples, and obtain a teacher model
                  ${f_{t}}$ by semi-supervised self-training. Then, we
                  introduce self-distillation method to enable
                  knowledge distillation for the diagnosis of skin
                  lesions. Finally, we measure diagnostic
                  effectiveness in the context of label sparsity and
                  class imbalance. The experiments on skin lesion
                  images dataset ISIC2018 shows that SISLD achieves
                  significant improvements in AUC, Accuracy,
                  Specificity and Sensitivity.}
}

@InProceedings{li22-4,
  title =	 {Unsupervised Photo-to-Caricature Generation with
                  Adaptive Select Layer-Instance Normalization and
                  Semi-cycle Consistency},
  author =	 {Zhiwei,Li and Weiling, Cai and Cairun Wang},
  pages =	 {595-610},
  crossref =	 {acml22},
  abstract =	 {Unpaired photo to caricature generation is a
                  challenging but meaningful task. Generating high
                  quality caricatures with rich texture/color and
                  plausible exaggeration is important. Previous
                  methods often respectively deal with the shape
                  transformation and texture/color style. We argue
                  that shape transformation can be treated as same as
                  texture/color. Thereby, shape transformation and
                  texture/color can be transferred at the same
                  time. In this paper, we proposed a new method namely
                  AdsSe-GAN for photo-to-caricature generation, which
                  consists of a new normalization function called
                  AdaSLIN and a new semi-cycle consistency loss. The
                  AdaSLIN adaptively selects Layer Normalization or
                  Instance Normalization to simultaneously transfer
                  texture/color and shape transformation. Besides we
                  present semi-cycle consistency loss which only
                  imposes L1 norm on caricature-to-photo process,
                  which is different from existing methods that apply
                  cycle consistency loss to preserve the original
                  domain information. In fact, while generating
                  caricature, taking no account of the cycle
                  restriction makes our model generate caricature with
                  more distinct exaggeration and higher
                  quality. Experimental results on a public caricature
                  dataset, WebCaricature, show the effectiveness of
                  our proposed method compared with the
                  state-of-the-art models.}
}

@InProceedings{singh22,
  title =	 {Autonomous Myocardial Infarction Detection from
                  Electrocardiogram with a Multi Label Classification
                  Approach},
  author =	 {Singh, Vishwa Mohan and Saran, Vibhor and Kadambi,
                  Pooja},
  pages =	 {911-926},
  crossref =	 {acml22},
  abstract =	 {Myocardial Infarctions (MI) or heart attacks are
                  among the most common medical emergencies
                  globally. Such an episode often has mild or varied
                  symptoms, making it hard to diagnose and respond in
                  a timely manner. An electrocardiogram (ECG) is used
                  to analyze the heart's electrical activity and,
                  through this help, clinicians detect and localize a
                  heart attack. However, interpretation of the ECG is
                  made manually by trained professionals. In order to
                  make this diagnosis more efficient, multiple methods
                  have tried to automate the MI detection and
                  localization process. In this work, we aim to create
                  a more effective method of MI detection by
                  restructuring the localization as a multi-label
                  classification (MLC) problem, in which one set of
                  attributes can belong to one or more classes. For
                  this classification, features like the ST-deviation,
                  T wave amplitude, and R-S ratios have been extracted
                  and fed into the MLC model, which in our case, is a
                  chain classifier of random forest. This proposed
                  model will have five classes as the target, which
                  represent the locations where an MI can occur. Our
                  method achieves the best overall hamming accuracy of
                  81.49\% in a k-fold cross validation test, with the
                  highest accuracy for an individual class being
                  97.72\% for anterior.}
}

@InProceedings{hu22-1,
  title =	 {Learning Practical Communication Strategies in
                  Cooperative Multi-Agent Reinforcement Learning},
  author =	 {Hu, Diyi and Zhang, Chi and Prasanna, Viktor and
                  Krishnamachari, Bhaskar},
  pages =	 {467-482},
  crossref =	 {acml22},
  abstract =	 {In Multi-Agent Reinforcement Learning, communication
                  is critical to encourage cooperation among
                  agents. Communication in realistic wireless networks
                  can be highly unreliable due to network conditions
                  varying with agents' mobility, and stochasticity in
                  the transmission process. We propose a framework to
                  learn practical communication strategies by
                  addressing three fundamental questions: (1)
                  \emph{When}: Agents learn the timing of
                  communication based on not only message importance
                  but also wireless channel conditions. (2)
                  \emph{What}: Agents augment message contents with
                  wireless network measurements to better select the
                  game and communication actions. (3) \emph{How}:
                  Agents use a novel neural message encoder to
                  preserve all information from received messages,
                  regardless of the number and order of
                  messages. Simulating standard benchmarks under
                  realistic wireless network settings, we show
                  significant improvements in game performance,
                  convergence speed and communication efficiency
                  compared with state-of-the-art.}
}

@InProceedings{shen22,
  title =	 {Temporal aware Multi-Interest Graph Neural Network
                  for Session-based Recommendation},
  author =	 {Shen, Qi and Zhu, Shixuan and Pang, Yitong and
                  Zhang, Yiming and Wei, Zhihua},
  crossref =	 {acml22},
  abstract =	 {Session-based recommendation (SBR) is a challenging
                  task, which aims at recommending next items based on
                  anonymous interaction sequences. Despite the
                  superior performance of existing methods for SBR,
                  there are still several limitations: (i) Almost all
                  existing works concentrate on single interest
                  extraction and fail to disentangle multiple
                  interests of user, which easily results in
                  suboptimal representations for SBR. (ii)
                  Furthermore, previous methods also ignore the
                  multi-form temporal information, which is
                  significant signal to obtain current intention for
                  SBR. To address the limitations mentioned above, we
                  propose a novel method, called Temporal aware
                  Multi-Interest Graph Neural Network (TMI-GNN) to
                  disentangle multi-interest and yield refined
                  intention representations with the injection of two
                  level temporal information. Specifically, by
                  appending multiple interest nodes, we construct a
                  multi-interest graph for current session, and adopt
                  the GNNs to model the item-item relation to capture
                  adjacent item transitions, item-interest relation to
                  disentangle the multi-interests, and interest-item
                  relation to refine the item
                  representation. Meanwhile, we incorporate item-level
                  time interval signals to guide the item information
                  propagation, and interest-level time distribution
                  information to assist the scattering of interest
                  information. Experiments on three benchmark datasets
                  demonstrate that TMI-GNN outperforms other
                  state-of-the-art methods consistently.}
}

@InProceedings{wang22-1,
  title =	 {Constrained Contrastive Reinforcement Learning},
  author =	 {Wang, Haoyu and Yang, Xinrui and Wang, Yuhang and
                  Lan Xuguang},
  pages =	 {1070-1084},
  crossref =	 {acml22},
  abstract =	 {Learning to control from complex observations
                  remains a major challenge in the application of
                  model-based reinforcement learning (MBRL). Existing
                  MBRL methods apply contrastive learning to replace
                  pixel-level reconstruction, improving the
                  performance of the latent world model. However,
                  previous contrastive learning approaches in MBRL
                  fail to utilize task-relevant information, making it
                  difficult to aggregate observations with the same
                  task-relevant information but the different
                  task-irrelevant information in latent space. In this
                  work, we first propose Constrained Contrastive
                  Reinforcement Learning (C2RL), an MBRL method that
                  learns a world model through a combination of two
                  contrastive losses based on latent dynamics and
                  task-relevant state abstraction respectively,
                  utilizing reward information to accelerate model
                  learning. Then, we propose a hyperparameter $\beta$
                  to balance two kinds of contrastive losses to
                  strengthen the representation ability of the latent
                  dynamics. The experimental results show that our
                  approach outperforms state-of-the-art methods in
                  both the natural video and standard background
                  setting on challenging DMControl tasks.}
}

@InProceedings{achenchabe22,
  title =	 {When to Classify Events in Open Times Series?},
  author =	 {Achenchabe, Youssef and Bondu, Alexis and
                  Cornu\'ejols Antoine and Lemaire Vincent},
  pages =	 {1-16},
  crossref =	 {acml22},
  abstract =	 {In numerous applications, for instance in predictive
                  maintenance, there is a pression to predict events
                  ahead of time with as much accuracy as possible
                  while not delaying the decision unduly. This
                  translates in the optimization of a trade-off
                  between earliness and accuracy of the decisions,
                  that has been the subject of research for time
                  series of finite length and with a unique label. And
                  this has led to powerful algorithms for Early
                  Classification of Time Series (ECTS). This paper,
                  for the first time, investigates such a trade-off
                  when events of different classes occur in a
                  streaming fashion, with no predefined end.  In the
                  Early Classification in Open Time Series problem
                  (ECOTS), the task is to predict events, i.e. their
                  class and time interval, at the moment that
                  optimizes the accuracy vs. earliness
                  trade-off. Interestingly, we find that ECTS
                  algorithms can be sensibly adapted in a principled
                  way to this new problem.  We illustrate our
                  methodology by transforming two state-of-the-art
                  ECTS algorithms for the ECOTS scenario.Among the
                  wide variety of applications that this new approach
                  opens up, we develop here a predictive maintenance
                  use case that optimizes alarm triggering times, thus
                  demonstrating the power of this new approach. }
}

@InProceedings{wu22,
  title =	 {Pose Guided Human Image Synthesis with Partially
                  Decoupled GAN},
  author =	 {Wu, Jianhan and Si, Shijing and Wang, Jianzong and
                  Qu, Xiaoyang and Xiao Jing},
  pages =	 {1133-1148},
  crossref =	 {acml22},
  abstract =	 {Pose Guided Human Image Synthesis (PGHIS) is a
                  challenging task of transforming a human image from
                  the reference pose to a target pose while preserving
                  its style. Most existing methods encode the texture
                  of the whole reference human image into a latent
                  space, and then utilize a decoder to synthesize the
                  image texture of the target pose. However, it is
                  difficult to recover the detailed texture of the
                  whole human image. To alleviate this problem, we
                  propose a method by decoupling the human body into
                  several parts (\emph{e.g.}, hair, face, hands, feet,
                  \emph{etc.}) and then using each of these parts to
                  guide the synthesis of a realistic image of the
                  person, which preserves the detailed information of
                  the generated images. In addition, we design a
                  multi-head attention-based module for PGHIS. Because
                  most convolutional neural network-based methods have
                  difficulty in modeling long-range dependency due to
                  the convolutional operation, the long-range modeling
                  capability of attention mechanism is more suitable
                  than convolutional neural networks for pose transfer
                  task, especially for sharp pose
                  deformation. Extensive experiments on Market-1501
                  and DeepFashion datasets reveal that our method
                  almost outperforms other existing state-of-the-art
                  methods in terms of both qualitative and
                  quantitative metrics.}
}

@InProceedings{dupe22,
  title =	 {Kernelized multi-graph matching},
  author =	 {Dup{\'e}, Fran{\c c}ois-Xavier and Yadav, Rohit and
                  Auzias, Guillaume and Takerkart, Sylvain},
  pages =	 {311-326},
  crossref =	 {acml22},
  abstract =	 {Multigraph matching is a recent variant of the graph
                  matching problem. In this framework, the
                  optimization procedure considers several graphs and
                  enforces the consistency of the matches along the
                  graphs. This constraint can be formalized as a cycle
                  consistency across the pairwise permutation
                  matrices, which implies the definition of a universe
                  of vertex (Pachauri et al., 2013). The label of each
                  vertex is encoded by a sparse vector and the
                  dimension of this space corresponds to the rank of
                  the bulk permutation matrix, the matrix built from
                  the aggregation of all the pairwise permutation
                  matrices. The matching problem can then be
                  formulated as a non-convex quadratic optimization
                  problem (QAP) under constraints imposed on the rank
                  and the permutations. In this paper, we introduce a
                  novel kernelized multigraph matching technique that
                  handles vectors of attributes on both the vertices
                  and edges of the graphs, while maintaining a low
                  memory usage. We solve the QAP problem using a
                  projected power optimization approach and propose
                  several projectors leading to improved stability of
                  the results. We provide several experiments
                  showingthat our method is competitive against other
                  unsupervised methods.}
}

@InProceedings{tian22,
  title =	 {FLVoogd: Robust And Privacy Preserving Federated
                  Learning},
  author =	 {Yuhang, Tian and Rui, Wang and Yanqi, Qiao and
                  Emmanouil, Panaousis and Kaitai, Liang},
  pages =	 {1022-1037},
  crossref =	 {acml22},
  abstract =	 {In this work, we propose FLVoogd, an updated
                  federated learning method in which servers and
                  clients collaboratively eliminate Byzantine attacks
                  while preserving privacy. In particular, servers use
                  automatic Density-based Spatial Clustering of
                  Applications with Noise (DBSCAN) combined with
                  Secure Multi-party Computation (SMPC) to cluster the
                  benign majority without acquiring sensitive personal
                  information. Meanwhile, clients build dual models
                  and perform test-based distance controlling to
                  adjust their local models toward the global one to
                  achieve personalizing.  Our framework is automatic
                  and adaptive that servers/clients don't need to tune
                  the parameters during the training. In addition, our
                  framework leverages SMPC's operations, including
                  multiplications, additions, and comparisons, where
                  costly operations, like division and square root,
                  are not required. Evaluations are carried out on
                  some conventional datasets from the image
                  classification field. The result shows that FLVoogd
                  can effectively reject malicious uploads in most
                  scenarios; meanwhile, it avoids data leakage from
                  the server side.}
}

@InProceedings{yi22,
  title =	 {Sliced Wasserstein variational inference},
  author =	 {Yi, Mingxuan and Liu, Song},
  pages =	 {1213-1228},
  crossref =	 {acml22},
  abstract =	 {Variational Inference approximates an unnormalized
                  distribution via the minimization of
                  Kullback-Leibler (KL) divergence. Although this
                  divergence is efficient for computation and has been
                  widely used in applications, it suffers from some
                  unreasonable properties. For example, it is not a
                  proper metric, i.e., it is non-symmetric and does
                  not preserve the triangle inequality. On the other
                  hand, optimal transport distances recently have
                  shown some advantages over KL divergence. With the
                  help of these advantages, we propose a new
                  variational inference method by minimizing sliced
                  Wasserstein distance--a valid metric arising from
                  optimal transport. This sliced Wasserstein distance
                  can be approximated simply by running MCMC but
                  without solving any optimization problem. Our
                  approximation also does not require a tractable
                  density function of variational distributions so
                  that approximating families can be amortized by
                  generators like neural networks. Furthermore, we
                  provide an analysis of the theoretical properties of
                  our method. Experiments on synthetic and real data
                  are illustrated to show the performance of the
                  proposed method.}
}
@InProceedings{dai22,
  title =	 {Multiple Imputation with Neural Network Gaussian
                  Process for High-dimensional Incomplete Data},
  author =	 {Dai, Zongyu and Bu, Zhiqi and Long, Qi},
  pages =	 {265-279},
  crossref =	 {acml22},
  abstract =	 {Missing data are ubiquitous in real world
                  applications and, if not adequately handled, may
                  lead to the loss of information and biased findings
                  in downstream analysis. Particularly,
                  high-dimensional incomplete data with a moderate
                  sample size, such as analysis of multi-omics data,
                  present daunting challenges. Imputation is arguably
                  the most popular method for handling missing data,
                  though existing imputation methods have a number of
                  limitations. Single imputation methods such as
                  matrix completion methods do not adequately account
                  for imputation uncertainty and hence would yield
                  improper statistical inference. In contrast,
                  multiple imputation (MI) methods allow for proper
                  inference but existing methods do not perform well
                  in high-dimensional settings. Our work aims to
                  address these significant methodological gaps,
                  leveraging recent advances in neural network
                  Gaussian process (NNGP) from a Bayesian
                  viewpoint. We propose two NNGP-based MI methods,
                  namely MI-NNGP, that can apply multiple imputations
                  for missing values from a joint (posterior
                  predictive) distribution. The MI-NNGP methods are
                  shown to significantly outperform existing
                  state-of-the-art methods on synthetic and real
                  datasets, in terms of imputation error, statistical
                  inference, robustness to missing rates, and
                  computation costs, under three missing data
                  mechanisms, MCAR, MAR, and MNAR.}
}

@InProceedings{anirudh22,
  title =	 {Out of Distribution Detection via Neural Network
                  Anchoring},
  author =	 {Anirudh, Rushil and Thiagarajan, Jayaraman J.},
  pages =	 {32-47},
  crossref =	 {acml22},
  abstract =	 {Our goal in this paper is to exploit heteroscedastic
                  temperature scaling as a calibration strategy for
                  out of distribution (OOD)
                  detection. Heteroscedasticity here refers to the
                  fact that the optimal temperature parameter for each
                  sample can be different, as opposed to conventional
                  approaches that use the same value for the entire
                  distribution. To enable this, we propose a new
                  training strategy called anchoring that can estimate
                  appropriate temperature values for each sample,
                  leading to state-of-the-art OOD detection
                  performance across several benchmarks. Using NTK
                  theory, we show that this temperature function
                  estimate is closely linked to the epistemic
                  uncertainty of the classifier, which explains its
                  behavior. In contrast to some of the best-performing
                  OOD detection approaches, our method does not
                  require exposure to additional outlier datasets,
                  custom calibration objectives, or model
                  ensembling. Through empirical studies with different
                  OOD detection settings -- far OOD, near OOD, and
                  semantically coherent OOD - we establish a highly
                  effective OOD detection approach.}
}

@InProceedings{nakamura22,
  title =	 {Robust computation of optimal transport by
                  $\beta$-potential regularization},
  author =	 {Nakamura, Shintaro and Bao, Han and Sugiyama,
                  Masashi},
  pages =	 {770-785},
  crossref =	 {acml22},
  abstract =	 {Optimal transport (OT) has become a widely used tool
                  in the machine learning field to measure the
                  discrepancy between probability distributions. For
                  instance, OT is a popular loss function that
                  quantifies the discrepancy between an empirical
                  distribution and a parametric model. Recently, an
                  entropic penalty term and the celebrated Sinkhorn
                  algorithm have been commonly used to approximate the
                  original OT in a computationally efficient
                  way. However, since the Sinkhorn algorithm runs a
                  projection associated with the Kullback-Leibler
                  divergence, it is often vulnerable to outliers. To
                  overcome this problem, we propose regularizing OT
                  with the $\beta$-potential term associated with the
                  so-called $\beta$-divergence, which was developed in
                  robust statistics. Our theoretical analysis reveals
                  that the $\beta$-potential can prevent the mass from
                  being transported to outliers. We experimentally
                  demonstrate that the transport matrix computed with
                  our algorithm helps estimate a probability
                  distribution robustly even in the presence of
                  outliers. In addition, our proposed method can
                  successfully detect outliers from a contaminated
                  dataset.}
}

@InProceedings{pandey22,
  title =	 {On the Interpretability of Attention Networks},
  author =	 {Pandey,Lakshmi Narayan and Vashisht, Rahul and
                  Ramaswamy, Harish G.},
  pages =	 {832-847},
  crossref =	 {acml22},
  abstract =	 {Attention mechanisms form a core component of
                  several successful deep learning architectures, and
                  are based on one key idea: ``The output depends only
                  on a small (but unknown) segment of the input.'' In
                  several practical applications like image captioning
                  and language translation, this is mostly true. In
                  trained models with an attention mechanism, the
                  outputs of an intermediate module that encodes the
                  segment of input responsible for the output is often
                  used as a way to peek into the `reasoning' of the
                  network. We make such a notion more precise for a
                  variant of the classification problem that we term
                  selective dependence classification (SDC) when used
                  with attention model architectures. Under such a
                  setting, we demonstrate various error modes where an
                  attention model can be accurate but fail to be
                  interpretable, and show that such models do occur as
                  a result of training. We illustrate various
                  situations that can accentuate and mitigate this
                  behaviour. Finally, we use our objective definition
                  of interpretability for SDC tasks to evaluate a few
                  attention model learning algorithms designed to
                  encourage sparsity and demonstrate that these
                  algorithms help improve interpretability.}
}

@InProceedings{obermair22,
  title =	 {Example or Prototype? Learning Concept-Based
                  Explanations in Time-Series},
  author =	 {Obermair, Christoph and Fuchs, Alexander and
                  Pernkopf, Franz and Felsberger, Lukas and Apollonio,
                  Andrea and Wollmann, Daniel},
  pages =	 {816-831},
  crossref =	 {acml22},
  abstract =	 {With the continuous increase of deep learning
                  applications in safety critical systems, the need
                  for an interpretable decision-making process has
                  become a priority within the research
                  community. While there are many existing explainable
                  artificial intelligence algorithms, a systematic
                  assessment of the suitability of global explanation
                  methods for different applications is not
                  available. In this paper, we respond to this demand
                  by systematically comparing two existing global
                  concept-based explanation methods with our proposed
                  global, model-agnostic concept-based explanation
                  method for time-series data. This method is based on
                  an autoencoder structure and derives abstract global
                  explanations called "prototypes". The results of a
                  human user study and a quantitative analysis show a
                  superior performance of the proposed method, but
                  also highlight the necessity of tailoring
                  explanation methods to the target audience of
                  machine learning models.}
}

@InProceedings{tan22,
  title =	 {CVaR-Regret Bounds for Multi-armed Bandits},
  author =	 {Chenmien Tan and Paul Weng},
  pages =	 {974-989},
  crossref =	 {acml22},
  abstract =	 {In contrast to risk-averse multi-armed bandit (MAB),
                  where one aims for a best risk-sensitive arm while
                  having a risk-neutral attitude when running the
                  risk-averse MAB algorithm, in this paper, we aim for
                  a best arm with respect to the mean like in the
                  standard MAB, but we adopt a risk-averse attitude
                  when running a standard MAB algorithm. Conditional
                  value-at-risk (CVaR) of the regret is adopted as the
                  metric to evaluate the performance of algorithms,
                  which is an extension of the traditional expected
                  regret minimization framework. For this new problem,
                  we revisit several classic algorithms for stochastic
                  and non-stochastic bandits, UCB, MOSS, and Exp3-IX
                  with its variants and propose parameters with good
                  theoretically guaranteed CVaR-regret, which match
                  the results of the expected regret and achieve
                  (nearly-)optimality up to constant. In the
                  non-stochastic setting, we show that implicit
                  exploration achieves a trade-off between the
                  variability of the regret and the regret in
                  expectation. Numerical experiments are conducted to
                  validate our results.}
}

@InProceedings{huang22,
  title =	 {3D Manifold Topology Based Medical Image Data
                  Augmentation},
  author =	 {Huang, Jisui and Lei, Na},
  pages =	 {499-514},
  crossref =	 {acml22},
  abstract =	 {Data augmentation is an effective and universal
                  technique for improving the generalization
                  performance of deep neural networks. Current data
                  augmentation implementations usually involve
                  geometric and photometric transformations. However,
                  none of them considers the topological information
                  in images, which is an important global invariant of
                  the three-dimensional manifold. In our
                  implementation, we design a novel method that finds
                  the generator of the first homology group,
                  i.e. closed loops cannot shrink to a point, of 3D
                  image and erases the bounding box of a random
                  loop. To the best of our knowledge, it is the first
                  time that data augmentation based on the first
                  homology group of the three-dimensional image is
                  applied in medical image augmentation. Our numerical
                  experiments demonstrate that the proposed approach
                  outperforms the state-of-the-art method.}
}

@InProceedings{chen22-3,
  title =	 {On the Convergence of Decentralized Adaptive
                  Gradient Methods},
  author =	 {Chen, Xiangyi and Karimi, Belhal and Zhao, Weijie
                  and Li, Ping},
  pages =	 {217-232},
  crossref =	 {acml22},
  abstract =	 {Adaptive gradient methods including Adam, AdaGrad,
                  and their variants have been very successful for
                  training deep learning models, such as neural
                  networks. Meanwhile, given the need for distributed
                  computing, distributed optimization algorithms are
                  rapidly becoming a focal point. With the growth of
                  computing power and the need for using machine
                  learning models on mobile devices, the communication
                  cost of distributed training algorithms needs
                  careful consideration. In this paper, we introduce
                  novel convergent decentralized adaptive gradient
                  methods and rigorously incorporate adaptive gradient
                  methods into decentralized training
                  procedures. Specifically, we propose a general
                  algorithmic framework that can convert existing
                  adaptive gradient methods to their decentralized
                  counterparts. In addition, we thoroughly analyze the
                  convergence behavior of the proposed algorithmic
                  framework and show that if a given adaptive gradient
                  method converges, under some specific conditions,
                  then its decentralized counterpart is also
                  convergent. We illustrate the benefit of our generic
                  decentralized framework on prototype methods,
                  AMSGrad and AdaGrad.}
}

@InProceedings{deng22-1,
  title =	 {BayesAdapter: Being Bayesian, Inexpensively and
                  Reliably, via Bayesian Fine-tuning},
  author =	 {Deng, Zhijie and Zhu, Jun},
  pages =	 {280-295},
  crossref =	 {acml22},
  abstract =	 {Despite their theoretical appealingness, Bayesian
                  neural networks (BNNs) are left behind in real-world
                  adoption, mainly due to persistent concerns on their
                  scalability, accessibility, and reliability. In this
                  work, we develop the BayesAdapter framework to
                  relieve these concerns. In particular, we propose to
                  adapt pre-trained deterministic NNs to be
                  variational BNNs via cost-effective Bayesian
                  fine-tuning. Technically, we develop a modularized
                  implementation for the learning of variational BNNs,
                  and refurbish the generally applicable exemplar
                  reparameterization trick through exemplar
                  parallelization to efficiently reduce the gradient
                  variance in stochastic variational inference. Based
                  on the the lightweight Bayesian learning paradigm,
                  we conduct extensive experiments on a variety of
                  benchmarks, and show that our method can
                  consistently induce posteriors with higher quality
                  than competitive baselines, yet significantly
                  reducing training overheads.}
}

@InProceedings{zhou22-1,
  title =	 {A Novel Differentiable Mixed-Precision Quantization
                  Search Framework for Alleviating the Matthew Effect
                  and Improving Robustness},
  author =	 {Zhou, Hengyi and He, Hongyi and Liu, Wanchen, and
                  Li, Yuhai and Zhang, Haonan and Liu, Longjun},
  pages =	 {1277-1292},
  crossref =	 {acml22},
  abstract =	 {Network quantization is an effective and widely-used
                  model compression technique. Recently, several works
                  apply differentiable neural architectural search
                  (NAS) methods to mixed-precision quantization (MPQ)
                  and achieve encouraging results. However, the nature
                  of differentiable architecture search can lead to
                  the Matthew Effect in the mixed-precision. The
                  candidates with higher bit-widths would be trained
                  maturely earlier while the candidates with lower
                  bit-widths may never have the chance to express the
                  desired function. To address this issue, we propose
                  a novel mixed-precision quantization framework. The
                  mixed-precision search is resolved as a distribution
                  learning problem, which alleviates the Matthew
                  effect and improves the generalization
                  ability. Meanwhile, different from generic
                  differentiable NAS methods, search space will grow
                  rapidly as the depth of the network increases in the
                  mixed-precision quantization search. This makes the
                  supernet harder to train and the search process
                  unstable. To this end, we add a skip connection with
                  a gradually decreasing architecture weight between
                  convolutional layers in the supernet to improve
                  robustness. The skip connection will help the
                  optimization of the search process and will not
                  participate in the bit width competition. Extensive
                  experiments on CIFAR-10 and ImageNet demonstrate the
                  effectiveness of the proposed methods. For example,
                  when quantizing ResNet-50 on ImageNet, we achieve a
                  state-of-the-art 156.10x Bitops compression rate
                  while maintaining a 75.87$\%$ accuracy.}
}

@InProceedings{hu22-2,
  title =	 {Adversarial Laser Spot: Robust and Covert
                  Physical-World Attack to DNNs},
  author =	 {Hu, Chengyin and Wang, Yilong and Tiliwalidi,
                  Kalibinuer and Li, Wen},
  pages =	 {483-498},
  crossref =	 {acml22},
  abstract =	 {Most existing deep neural networks (DNNs) are easily
                  disturbed by slight noise. However, there are few
                  researches on physical attacks by deploying lighting
                  equipment. The light-based physical attacks has
                  excellent covertness, which brings great security
                  risks to many vision-based applications (such as
                  self-driving). Therefore, we propose a light-based
                  physical attack, called adversarial laser spot
                  (AdvLS), which optimizes the physical parameters of
                  laser spots through genetic algorithm to perform
                  physical attacks. It realizes robust and covert
                  physical attack by using low-cost laser
                  equipment. As far as we know, AdvLS is the first
                  light-based physical attack that perform physical
                  attacks in the daytime. A large number of
                  experiments in the digital and physical environments
                  show that AdvLS has excellent robustness and
                  covertness. In addition, through in-depth analysis
                  of the experimental data, we find that the
                  adversarial perturbations generated by AdvLS have
                  superior adversarial attack migration. The
                  experimental results show that AdvLS impose serious
                  interference to advanced DNNs, we call for the
                  attention of the proposed AdvLS.}
}

@InProceedings{xiao22-2,
  title =	 {Semantic Cross Attention for Few-shot Learning},
  author =	 {Bin Xiao and Chien-Liang Liu and Wen-Hoar Hsaio},
  pages =	 {1165-1180},
  crossref =	 {acml22},
  abstract =	 {Few-shot learning (FSL) has attracted considerable
                  attention recently. Among existing approaches, the
                  metric-based method aims to train an embedding
                  network that can make similar samples close while
                  dissimilar samples as far as possible and achieves
                  promising results. FSL is characterized by using
                  only a few images to train a model that can
                  generalize to novel classes in image classification
                  problems, but this setting makes it difficult to
                  learn the visual features that can identify the
                  images' appearance variations. The model training is
                  likely to move in the wrong direction, as the images
                  in an identical semantic class may have dissimilar
                  appearances, whereas the images in different
                  semantic classes may share a similar appearance. We
                  argue that FSL can benefit from additional semantic
                  features to learn discriminative feature
                  representations. Thus, this study proposes a
                  multi-task learning approach to view semantic
                  features of label text as an auxiliary task to help
                  boost the performance of the FSL task. Our proposed
                  model uses word-embedding representations as
                  semantic features to help train the embedding
                  network and a semantic cross-attention module to
                  bridge the semantic features into the typical visual
                  modal. The proposed approach is simple, but produces
                  excellent results. We apply our proposed approach to
                  two previous metric-based FSL methods, all of which
                  can substantially improve performance. The source
                  code for our model is accessible from github.}
}

@InProceedings{frikha22,
  title =	 {Towards Data-Free Domain Generalization},
  author =	 {Frikha, Ahmed and Chen, Haokun and Krompa{\ss},
                  Denis and Runkler, Thomas and Tresp, Volker},
  pages =	 {327-342},
  crossref =	 {acml22},
  abstract =	 {In this work, we investigate the unexplored
                  intersection of domain generalization (DG) and
                  data-free learning. In particular, we address the
                  question: How can knowledge contained in models
                  trained on different source domains be merged into a
                  single model that generalizes well to unseen target
                  domains, in the absence of source and target domain
                  data? Machine learning models that can cope with
                  domain shift are essential for real-world scenarios
                  with often changing data distributions. Prior DG
                  methods typically rely on using source domain data,
                  making them unsuitable for private decentralized
                  data. We define the novel problem of Data-Free
                  Domain Generalization (DFDG), a practical setting
                  where models trained on the source domains
                  separately are available instead of the original
                  datasets, and investigate how to effectively solve
                  the domain generalization problem in that case. We
                  propose DEKAN, an approach that extracts and fuses
                  domain-specific knowledge from the available teacher
                  models into a student model robust to domain
                  shift. Our empirical evaluation demonstrates the
                  effectiveness of our method which achieves first
                  state-of-the-art results in DFDG by significantly
                  outperforming data-free knowledge distillation and
                  ensemble baselines.}
}

@InProceedings{wimalawarne22,
  title =	 {Layer-wise Adaptive Graph Convolution Networks Using
                  Generalized Pagerank},
  author =	 {Wimalawarne, Kishan and Suzuki, Taiji},
  pages =	 {1117-1132},
  crossref =	 {acml22},
  abstract =	 { We investigate adaptive layer-wise graph
                  convolution in deep GCN models. We propose AdaGPR to
                  learn generalized Pageranks at each layer of a GCNII
                  network to induce adaptive convolution. We show that
                  the generalization bound for AdaGPR is bounded by a
                  polynomial of the eigenvalue spectrum of the
                  normalized adjacency matrix in the order of the
                  number of generalized Pagerank coefficients.  By
                  analysing the generalization bounds we show that
                  oversmoothing depends on both the convolutions by
                  the higher orders of the normalized adjacency matrix
                  and the depth of the model.  We performed
                  evaluations on node-classification using benchmark
                  real data and show that AdaGPR provides improved
                  accuracies compared to existing graph convolution
                  networks while demonstrating robustness against
                  oversmoothing. Further, we demonstrate that analysis
                  of coefficients of layer-wise generalized Pageranks
                  allows us to qualitatively understand convolution at
                  each layer enabling model interpretations.}
}

@InProceedings{zhou22-2,
  title =	 {Multi-scale Progressive Gated Transformer for
                  Physiological Signal Classification},
  author =	 {Zhou, Wei and Wang, Hao and Zhang, Yiling and Long,
                  Cheng and Yang, Yan and Wang, Dongjie},
  pages =	 {1293-1308},
  crossref =	 {acml22},
  abstract =	 {Physiological signal classification is of great
                  significance for health monitoring and medical
                  diagnosis. Deep learning-based methods (e.g. RNN and
                  CNN) have been used in this domain to obtain
                  reliable predictions. However, the performance of
                  existing methods is constrained by the long-term
                  dependence and irregular vibration of the univariate
                  physiological signal sequence. To overcome these
                  limitations, this paper proposes a Multi-scale
                  Progressive Gated Transformer (MPGT) model to learn
                  multi-scale temporal representations for better
                  physiological signal classification. The key
                  novelties of MPGT are the proposed Multi-scale
                  Temporal Feature extraction (MTF) and Progressive
                  Gated Transformer (PGT). The former adopts coarse-
                  and fine-grained feature extractors to project the
                  input signal data into different temporal
                  granularity embedding spaces and the latter
                  integrates such multi-scale information for data
                  representation. Classification task is then
                  conducted on the learned
                  representations. Experimental results on real-world
                  datasets demonstrate the superiority of the proposed
                  model.}
}

@InProceedings{mohammed22,
  title =	 {Bootstrapping a high quality multilingual multimodal
                  dataset for Bletchley},
  author =	 {Mohammed, Owais Khan and Aggarwal, Kriti and Liu,
                  Qiang and Singhal, Saksham and Bjorck, Johan and
                  Som, Subhojit},
  pages =	 {738-753},
  crossref =	 {acml22},
  abstract =	 {Vision-language models have recently made impressive
                  strides, primarily driven by large-scale training on
                  web data. While pioneering works such as CLIP and
                  ALIGN show significant improvements, these are
                  focused on English data as it is easy to source them
                  from the web. Towards serving non-English-speaking
                  demographics, we consider various methods for
                  generating multilingual data and find that a simple
                  bootstrapping mechanism works surprisingly
                  well. Specifically, just using English image
                  captions data and text-only multilingual translation
                  pairs we train a fairly strong multilingual
                  vision-language model and then leverage it to create
                  a much cleaner version of the multilingual image
                  captions dataset we collected. We demonstrate that
                  this dataset which was used to train Bletchley
                  result in a strong multi-modal and multilingual
                  model which reaches strong performance across
                  several multilingual zero-shot tasks. Specifically,
                  Bletchley achieves state-of-the-art results on
                  multilingual COCO, Multi30k sets, IGLUE WIT and
                  xFlickr&CO datasets.}
}

@InProceedings{han22,
  title =	 {SNAIL: Semi-Separated Uncertainty Adversarial
                  Learning for Universal Domain Adaptation},
  author =	 {Zhongyi Han and Wan Su and Rundong He and Yilong
                  Yin},
  pages =	 {436-451},
  crossref =	 {acml22},
  abstract =	 { Universal domain adaptation (UniDA) is a new
                  sub-topic of unsupervised domain adaptation. It
                  handles the problem that the source or target domain
                  possibly has open-class samples. The inborn
                  challenge is to detect the open-class samples in the
                  test phase. Pioneering studies could be viewed as
                  dependent-detector-based methods. They cleverly
                  design efficient uncertainty metrics (\eg,
                  confidence, entropy, distance) based on the outputs
                  of domain adaptation models (predictor) to detect
                  open-class samples. However, they have a pain point
                  in setting extremely-sensitive and task-dependent
                  thresholds on the uncertainty metrics to filter
                  open-class samples. To bypass this pain point, we
                  propose a semi-separated-detector-based method,
                  Semi-Separated Uncertainty Adversarial Learning
                  (SNAIL). We build a semi-separated uncertainty
                  decision-maker to enable sensitive-threshold-free
                  detection. It receives multiple uncertainty metrics
                  as attributes and separately learns the thresholds
                  of uncertainty metrics in a multi-level decision
                  rule. For some challenging tasks, the uncertainty
                  margins between common and open classes are subtle,
                  leading to difficulty learning optimal decision
                  rules. We present the uncertainty separation loss to
                  enlarge the uncertainty margin. Further, forcibly
                  aligning the distributions could incorrectly align
                  the open classes to common classes.  Thanks to the
                  open-class detection strategy, we design the
                  conditional-weighted adversarial loss that
                  adversarially and selectively matches the feature
                  distributions to defeat the distribution
                  misalignment problem. Extensive experiments show
                  that SNAIL remarkably outperforms the
                  state-of-the-art domain adaptation methods, with
                  over 25\% improvements in open-class detection
                  accuracy for some tasks.}
}

@InProceedings{wang22-3,
  title =	 {Margin Calibration for Long-Tailed Visual
                  Recognition},
  author =	 {Wang, Yidong and Zhang, Bowen and Hou, Wenxin and
                  Wu, Zhen and Wang, Jindong and Shinozaki, Takahiro},
  pages =	 {1101-1116},
  crossref =	 {acml22},
  abstract =	 {Long-tailed visual recognition tasks pose great
                  challenges for neural networks on how to handle the
                  imbalanced predictions between head (common) and
                  tail (rare) classes, i.e., models tend to classify
                  tail classes as head classes. While existing
                  research focused on data resampling and loss
                  function engineering, in this paper, we take a
                  different perspective: the classification
                  margins. We study the relationship between the
                  margins and logits and empirically observe that the
                  uncalibrated margins and logits are positively
                  correlated. We propose a simple yet effective MARgin
                  Calibration approach (MARC) to calibrate the margins
                  to obtain better logits. We validate MARC through
                  extensive experiments on common long-tailed
                  benchmarks including CIFAR-LT, ImageNet-LT,
                  Places-LT, and iNaturalist-LT. Experimental results
                  demonstrate that our MARC achieves favorable results
                  on these benchmarks. In addition, MARC is extremely
                  easy to implement with just three lines of code. We
                  hope this simple approach will motivate people to
                  rethink the uncalibrated margins and logits in
                  long-tailed visual recognition.}
}

@InProceedings{gulati22,
  title =	 {BeautifAI - Personalised Occasion-based Makeup
                  Recommendation},
  author =	 {Gulati, Kshitij and Verma, Gaurav and Mohania,
                  Mukesh and Kundu, Ashish},
  pages =	 {407-419},
  crossref =	 {acml22},
  abstract =	 {With the global metamorphosis of the beauty industry
                  and the rising demand for beauty products worldwide,
                  the need for a robust makeup recommendation system
                  has never been more. Despite the significant
                  advancements made towards personalised makeup
                  recommendation, the current research still falls
                  short of incorporating the context of occasion and
                  integrating feedback for users. In this work, we
                  propose BeautifAI, a novel recommendation system,
                  delivering personalised occasion-oriented makeup
                  recommendations to users. The proposed work’s novel
                  contributions, including incorporating occasion
                  context to makeup recommendation and a region-wise
                  method using neural embeddings, set our system apart
                  from the current work in makeup recommendation. We
                  also propose real-time makeup previews and
                  continuous makeup feedback to provide a more
                  personalised and interactive experience to users.}
}

@InProceedings{murad22,
  title =	 {Hashing2Vec: Fast Embedding Generation for
                  SARS-CoV-2 Spike Sequence Classification},
  author =	 {Murad Taslim and Chourasia Prakash and Ali Sarwan
                  and Patterson Murray},
  pages =	 {754-769},
  crossref =	 {acml22},
  abstract =	 { Due to the ongoing coronavirus (COVID-19) pandemic,
                  an unprecedented amount of SARS-CoV-2 sequence data
                  is available. The scale of this data has out-paced
                  traditional methods for its analysis, while
                  machine-learning approaches aimed at clustering and
                  classification of SARS-CoV-2 variants is becoming an
                  attractive alternative. Since the SARS-CoV-2 genome
                  is highly dimensional, considering the much smaller
                  spike region can save a great deal of processing.
                  As the spike protein mediates the attachment of the
                  coronavirus to the host cell, most of the newer and
                  more contagious variants can be characterized by
                  alterations to the spike protein; hence it is often
                  sufficient for characterizing the different
                  SARS-CoV-2 variants. Another important consideration
                  is to have a fast feature embedding generation,
                  which is the subject of this work.  Applying any
                  machine learning (ML) model to a biological sequence
                  requires first transforming it into a fixed-length
                  (numerical) form. While there exist several compact
                  embeddings for SARS-CoV-2 spike protein sequences,
                  the generation process is computationally expensive
                  since the features, added to the resulting vectors,
                  are indexed in a na\"{i}ve fashion.  To solve this
                  problem, we propose a fast and alignment-free
                  hashing-based approach to design a fixed-length
                  feature embedding for spike protein sequences,
                  called Hashing2Vec, which can be used as input to
                  any standard ML model. Using real-world data, we
                  show that the proposed embedding is not only
                  efficient to compute but also outperforms current
                  state-of-the-art embedding methods in terms of
                  classification accuracy. In terms of runtime, we
                  achieve up to a 99.8\% improvement in the
                  Hashing2Vec-based embedding generation as compared
                  to the baselines on a set of 7K spike amino acid
                  sequences. It also outperforms the baselines on this
                  data in terms of predictive performance and achieves
                  accuracy and ROC-AUC scores of 86\% and 84.4\%,
                  respectively.}
}

@InProceedings{hachiya22,
  title =	 {Position-dependent partial convolutions for
                  supervised spatial interpolation},
  author =	 {Hachiya, Hirotaka and Nagayoshi, Kotaro and Iwaki,
                  Asako and Maeda, Takahiro and Ueda, Naonori and
                  Fujiwara, Hiroyuki},
  pages =	 {420-435},
  crossref =	 {acml22},
  abstract =	 {Acquiring continuous spatial data, e.g., spatial
                  ground motion is essential to assess the damaged
                  area and appropriately assign rescue and medical
                  teams. To this purpose, spatial interpolation
                  methods have been developed to estimate the value of
                  unobserved points linearly from neighbor observed
                  values, i.e., inverse distance weighting and
                  Kriging. Recently, realistic spatial continuous
                  environmental data with various scenarios can be
                  generated by 3D finite difference methods with a
                  high-resolution structure model. It enables us to
                  collect supervised data even for unobserved
                  points. Along this line, we propose a framework of
                  supervised spatial interpolation and apply highly
                  advanced deep inpainting methods where we treat
                  spatially distributed observed points as a masked
                  image and non-linearly expand them through
                  convolutional encoder-decoder networks. However, the
                  property of translation invariance would avoid
                  locally fine-grained interpolation since the
                  relation between the target and surrounding
                  observation points varies over regions due to its
                  topography and subsurface structure. To overcome
                  this problem, we propose introducing
                  position-dependent convolution where kernel weights
                  are adjusted depending on their position on an image
                  based on the trainable position-feature map. We show
                  the effectiveness of our proposed method, called,
                  PoDIM (Position-dependent Deep Inpainting Method),
                  through experiments using simulated ground-motion
                  data.}
}

@InProceedings{bai22,
  title =	 {On the Episodic Difficulty of Few-shot Learning},
  author =	 {Bai, Yunwei and He, Zhenfeng and Hu, Junfeng},
  pages =	 {48-63},
  crossref =	 {acml22},
  abstract =	 {Dog vs. hot dog and dog vs. wolf, which one tends to
                  be a harder comparison task? While simple, this
                  question can be meaningful for few-shot
                  classification. Few-shot learning enables trained
                  models to recognize unseen classes through just a
                  few labelled samples. As such, trained few-shot
                  models usually have to possess the ability to assess
                  the similarity degree between the unlabelled and
                  labelled samples. In each few-shot learning episode,
                  a combination of the labelled support set and
                  unlabelled query set are sampled from the training
                  dataset for model-training. In the episodic settings
                  of few-shot learning, most algorithms draw the data
                  samples uniformly at random for training. However,
                  this approach disregards concepts of difficulty of
                  each training episode, which may make a difference.
                  After all, it is usually easier to differentiate
                  between a dog and a hot dog, versus the dog and a
                  wolf.  Therefore, in this paper, we delve into the
                  concept of episodic difficulty, or difficulty of
                  each training episode, discovering several insights
                  and proposing strategies to utilize the difficulty.
                  Firstly, defining episodic difficulty as a training
                  loss, we find and study the correlation between
                  episodic difficulty and visual similarity among data
                  samples in each episode.  Secondly, we assess the
                  respective usefulness of easy and difficult episodes
                  for the training process.  Lastly, based on the
                  assessment, we design a curriculum for few-shot
                  learning to support training with incremental
                  difficulty.  We observe that such an approach can
                  achieve faster convergence for few-shot algorithms,
                  reducing the average training time by around 50\%.
                  It can also make meta-learning algorithms achieve an
                  increase in final testing accuracy scores.}
}

@InProceedings{qiu22,
  title =	 {Interpretable Representation Learning from Temporal
                  Multi-view Data},
  author =	 {Qiu, Lin and Chinchilli, Vernon M. and Lin, Lin},
  pages =	 {864-879},
  crossref =	 {acml22},
  abstract =	 {In many scientific problems such as video
                  surveillance, modern genomics, and finance, data are
                  often collected from diverse measurements across
                  time that exhibit time-dependent heterogeneous
                  properties. Thus, it is important to not only
                  integrate data from multiple sources (called
                  multi-view data), but also to incorporate time
                  dependency for deep understanding of the underlying
                  system. We propose a generative model based on
                  variational autoencoder and a recurrent neural
                  network to infer the latent dynamics for multi-view
                  temporal data.  This approach allows us to identify
                  the disentangled latent embeddings across views
                  while accounting for the time factor. We invoke our
                  proposed model for analyzing three datasets on which
                  we demonstrate the effectiveness and the
                  interpretability of the model.}
}

@InProceedings{gong22,
  title =	 {Circulant-interactive Transformer with
                  Dimension-aware Fusion for Multimodal Sentiment
                  Analysis},
  author =	 {Gong, Peizhu and Liu, Jin and Zhang, Xiliang and Li,
                  Xingye and Yu, Zijun},
  pages =	 {391-406},
  crossref =	 {acml22},
  abstract =	 {Multimodal sentiment analysis (MSA) is gaining
                  traction as a critical tool for understanding human
                  behavior and enabling a wide range of
                  applications. Since data of different modalities
                  might lie in completely distinct spaces, it is very
                  challenging to perform effective fusion and analysis
                  from asynchronous multimodal streams. Most of
                  previous works focused on aligned fusion, which is
                  unpractical in real-world scenarios. The recent
                  Multimodal Transformer (MulT) approach attends to
                  model the correlations between elements from
                  different modalities in an unaligned
                  manner. However, it collects temporal information by
                  self-attention transformer which is a sequence
                  model, implying that interactions across distinct
                  time steps are not sufficient. In this paper, we
                  propose the Citculant-interactive Transformer
                  Network with dimension-aware fusion (CITN-DAF),
                  which enables parallel computation of different
                  modalities among different time steps and alleviates
                  inter-modal temporal sensitivity while preserving
                  intra-modal semantic order. By incorporating
                  circulant matrices into the cross-modal attention
                  mechanism, CITN-DAF is aimed to examine all
                  conceivable interactions between vectors of
                  different modalities. In addition, a dimension-aware
                  fusion method is presented, which projects feature
                  representations into different subspaces for an
                  in-depth fusion. We evaluate CITN-DAF on three
                  commonly used sentiment analysis benchmarks
                  including CMU-MOSEI, CMU-MOSI and IEMOCAP. Extensive
                  experimental results reveal that CITN-DAF is
                  superior in cross-modal semantic interactions and
                  outperforms the state-of-the-art multimodal
                  methods.}
}

@InProceedings{ma22-1,
  title =	 {Learning Disentangled Representation in Pruning for
                  Real-Time UAV Tracking},
  author =	 {Ma, Siyu and Liu, Yuting and Zeng, Dan and Liao,
                  Yaxin and Xu, Xiaoyu and Li, Shuiwang},
  pages =	 {690-705},
  crossref =	 {acml22},
  abstract =	 {Efficiency is a critical issue in UAV tracking
                  because of the limitations of computing resources,
                  battery capacity, and maximum load of unmanned
                  aerial vehicle (UAV). However, deep learning
                  (DL)-based trackers hardly achieve real-time
                  tracking on a single CPU despite their high tracking
                  precision. To the contrary, discriminative
                  correlation filters (DCF)-based trackers have high
                  efficiency but their precision is barely
                  satisfactory. Despite the precision is inferior,
                  DCF-based trackers instead of DL-based ones are
                  widely applied in UAV tracking to trade precision
                  for efficiency. This paper aims to improve the
                  efficiency of the DL-based tracker SiamFC++, in
                  particular, for UAV tracking using the model
                  compression technique, i.e., rank-based filter
                  pruning, which has not been well explored
                  before. Meanwhile, to combat the potential loss of
                  precision caused by pruning we exploit disentangled
                  representation learning to disentangle the output
                  feature of the backbone into two parts: the
                  identity-related features and the identity-unrelated
                  features. Only the identity-related features are
                  used for subsequent classification and regression
                  tasks to improve the effectiveness of the feature
                  representation. With the proposed disentangled
                  representation in pruning, we achieved higher
                  precisions when compressing the original model
                  SiamFC++ with a global pruning ratio of
                  0.5. Extensive experiments on four public UAV
                  benchmarks, i.e., UAV123@10fps, UAVDT, DTB70, and
                  Vistrone2018, show that the proposed tracker
                  DP-SiamFC++ strikes a remarkable balance between
                  efficiency and precision, and achieves
                  state-of-the-art performance in UAV tracking.}
}

@InProceedings{xue22,
  title =	 {Cross-Scale Context Extracted Hashing for
                  Fine-Grained Image Binary Encoding},
  author =	 {Xue, Xuetong and Shi, Jiaying and He, Xinxue and Xu,
                  Shenghui and Pan, Zhaoming},
  pages =	 {1197-1212},
  crossref =	 {acml22},
  abstract =	 {Deep hashing has been widely applied to large-scale
                  image retrieval tasks owing to efficient computation
                  and low storage cost by encoding high-dimensional
                  image data into binary codes. Since binary codes do
                  not contain as much information as float features,
                  the essence of binary encoding is preserving the
                  main context to guarantee retrieval
                  quality. However, the existing hashing methods have
                  great limitations on suppressing redundant
                  background information and accurately encoding from
                  Euclidean space to Hamming space by a simple sign
                  function. In order to solve these problems, a
                  Cross-Scale Context Extracted Hashing Network
                  (CSCE-Net) is proposed in this paper. Firstly, we
                  design a two-branch framework to capture
                  fine-grained local information while maintaining
                  high-level global semantic information. Besides,
                  Attention guided Information Extraction module (AIE)
                  is introduced between two branches, which suppresses
                  areas of low context information cooperated with
                  global sliding windows. Unlike previous methods, our
                  CSCE-Net learns a content-related Dynamic Sign
                  Function (DSF) to replace the original simple sign
                  function. Therefore, the proposed CSCE-Net is
                  context-sensitive and able to perform well on
                  accurate image binary encoding. We further
                  demonstrate that our CSCE-Net is superior to the
                  existing hashing methods, which improves retrieval
                  performance on standard benchmarks.}
}

@InProceedings{li22-5,
  title =	 {Robust Direct Learning for Causal Data Fusion},
  author =	 {Li, Xinyu and Li, Yilin and Cui, Qing and Li,
                  Longfei and Zhou, Jun},
  pages =	 {611-626},
  crossref =	 {acml22},
  abstract =	 {In the era of big data, the explosive growth of
                  multi-source heterogeneous data offers many exciting
                  challenges and opportunities for improving the
                  inference of conditional average treatment
                  effects. In this paper, we investigate homogeneous
                  and heterogeneous causal data fusion problems under
                  a general setting that allows for the presence of
                  source-specific covariates. We provide a direct
                  learning framework for integrating multi-source data
                  that separates the treatment effect from other
                  nuisance functions, and achieves double robustness
                  against certain misspecification. To improve
                  estimation precision and stability, we propose a
                  causal information-aware weighting function
                  motivated by theoretical insights from the
                  semiparametric efficiency theory; it assigns larger
                  weights to samples containing more causal
                  information with high interpretability. We introduce
                  a two-step algorithm, the weighted multi-source
                  direct learner, based on constructing a
                  pseudo-outcome and regressing it on covariates under
                  a weighted least square criterion; it offers us a
                  powerful tool for causal data fusion, enjoying the
                  advantages of easy implementation, double robustness
                  and model flexibility. In simulation studies, we
                  demonstrate the effectiveness of our proposed
                  methods in both homogeneous and heterogeneous causal
                  data fusion scenarios.}
}

@InProceedings{xiao22-1,
  title =	 {Probabilistic Fusion of Neural Networks that
                  Incorporates Global Information},
  author =	 {Xiao, Peng and Zhang, Biao and Cheng, Samuel and
                  Wei, Ke and Zhang, Shuqin},
  pages =	 {1149-1164},
  crossref =	 {acml22},
  abstract =	 {As one of the approaches in Federated Learning,
                  model fusion distills models trained on local
                  clients into a global model.  The previous method,
                  Probabilistic Federated Neural Matching (PFNM), can
                  match and fuse local neural networks with varying
                  global model sizes and data heterogeneity using the
                  Bayesian nonparametric framework. However, the
                  alternating optimization process applied by PFNM
                  causes absence of global neuron information. In this
                  paper, we propose a new method that extends PFNM by
                  introducing a Kullback-Leibler (KL) divergence
                  penalty, so that it can exploit information in both
                  local and global neurons. We show theoretically that
                  the extended PFNM with a penalty derived from KL
                  divergence can fix the drawback of PFNM by making a
                  balance between Euclidean distance and the prior
                  probability of neurons. Experiments on deep
                  fully-connected as well as deep convolutional neural
                  networks demonstrate that our new method outperforms
                  popular state-of-the-art federated learning methods
                  in both image classification and semantic
                  segmentation tasks.}
}

@InProceedings{nguyen22,
  title =	 {One Gradient Frank-Wolfe for Decentralized Online
                  Convex and Submodular Optimization},
  author =	 {Nguyen, Tuan-Anh and Kim Thang, Nguyen and Trystram,
                  Denis},
  pages =	 {802-815},
  crossref =	 {acml22},
  abstract =	 {Decentralized learning has been studied intensively
                  in recent years motivated by its wide applications
                  in the context of federated learning. The majority
                  of previous research focuses on the offline setting
                  in which the objective function is static. However,
                  the offline setting becomes unrealistic in numerous
                  machine learning applications that witness the
                  change of massive data. In this paper, we propose
                  \emph{decentralized online} algorithm for convex and
                  continuous DR-submodular optimization, two classes
                  of functions that are present in a variety of
                  machine learning problems. Our algorithms achieve
                  performance guarantees comparable to those in the
                  centralized offline setting. Moreover, on average,
                  each participant performs only a \emph{single}
                  gradient computation per time step. Subsequently, we
                  extend our algorithms to the bandit
                  setting. Finally, we illustrate the competitive
                  performance of our algorithms in real-world
                  experiments.}
}

@InProceedings{zheng22,
  title =	 {EENAS: An Eﬀicient Evolutionary Algorithm for Neural
                  Architecture Search},
  author =	 {Zheng Jian and Han Wenran and Zhang Ying and Ji
                  Shufan},
  pages =	 {1261-1276},
  crossref =	 {acml22},
  abstract =	 {Neural Architecture Search (NAS) has been widely
                  applied to automatic neural architecture
                  design. Traditional NAS methods often evaluate a
                  large number of architectures, leading to expensive
                  computation overhead.  To speed-up architecture
                  search, recent NAS methods try to employ network
                  estimation strategies for guidance of promising
                  architecture selection.  In this paper, we have
                  proposed an efficient evolutionary algorithm for
                  NAS, which adapts the most advanced proxy of
                  synthetic signal bases for architecture
                  estimation. Extensive experiments show that our
                  method outperforms state-of-the-art NAS methods, on
                  NAS-Bench-101 search space and NAS-Bench-201 search
                  space (CIFAR-10, CIFAR-100 and
                  ImageNet16-120). Compared with existing works, our
                  method could identify better architectures with
                  greatly reduced search time.}
}

@InProceedings{chowdhury22,
  title =	 {Value Function Approximations via Kernel Embeddings
                  for No-Regret Reinforcement Learning},
  author =	 {Chowdhury, Sayak Ray and Oliveira, Rafael},
  pages =	 {249-264},
  crossref =	 {acml22},
  abstract =	 {We consider the regret minimization problem in
                  reinforcement learning (RL) in the episodic setting.
                  In many real-world RL environments, the state and
                  action spaces are continuous or very large. Existing
                  approaches establish regret guarantees by either a
                  low-dimensional representation of the stochastic
                  transition model or an approximation of the
                  $Q$-functions. However, the understanding of
                  function approximation schemes for state-value
                  functions largely remains missing. In this paper, we
                  propose an online model-based RL algorithm, namely
                  the CME-RL, that learns embeddings of the
                  state-transition distribution in a reproducing
                  kernel Hilbert space while carefully balancing the
                  exploitation-exploration tradeoff. We demonstrate
                  the efficiency of our algorithm by proving a
                  frequentist (worst-case) regret bound that is of
                  order
                  $\tilde{O}\big(H\gamma_N\sqrt{N}\big)$\footnote{
                  $\tilde{O}(\cdot)$ hides only absolute constant and
                  poly-logarithmic factors.}, where $H$ is the episode
                  length, $N$ is the total number of time steps and
                  $\gamma_N$ is an information theoretic quantity
                  relating the effective dimension of the state-action
                  feature space. Our method bypasses the need for
                  estimating transition probabilities and applies to
                  any domain on which kernels can be defined. It also
                  brings new insights into the general theory of
                  kernel methods for approximate inference and RL
                  regret minimization.}
}

@InProceedings{li22-3,
  title =	 {AIIR-MIX: Multi-Agent Reinforcement Learning Meets
                  Attention Individual Intrinsic Reward Mixing
                  Network},
  author =	 {Li, Wei and Liu, Weiyan and Shao, Shitong and Huang,
                  Shiyi},
  pages =	 {579-594},
  crossref =	 {acml22},
  abstract =	 {Deducing the contribution of each agent and
                  assigning the corresponding reward to them is a
                  crucial problem in cooperative Multi-Agent
                  Reinforcement Learning (MARL). Previous studies try
                  to resolve the issue through designing an intrinsic
                  reward function, but the intrinsic reward is simply
                  combined with the environment reward by summation in
                  these studies, which makes the performance of their
                  MARL framework unsatisfactory. We propose a novel
                  method named Attention Individual Intrinsic Reward
                  Mixing Network (AIIR-MIX) in MARL, and the
                  contributions of AIIR-MIX are listed as follows:
                  \textbf{(a)} we construct a novel intrinsic reward
                  network based on the attention mechanism to make
                  teamwork more effective. \textbf{(b)} we propose a
                  Mixing network that is able to combine intrinsic and
                  extrinsic rewards non-linearly and dynamically in
                  response to changing conditions of the
                  environment. We compare AIIR-MIX with many
                  State-Of-The-Art (SOTA) MARL methods on battle games
                  in StarCraft II. And the results demonstrate that
                  AIIR-MIX performs admirably and can defeat the
                  current advanced methods on average test win
                  rate. To validate the effectiveness of AIIR-MIX, we
                  conduct additional ablation studies. The results
                  show that AIIR-MIX can dynamically assign each agent
                  a real-time intrinsic reward in accordance with
                  their actual contribution.}
}

@InProceedings{schwabe22,
  title =	 {AFRNN: Stable RNN with Top Down Feedback and
                  Antisymmetry},
  author =	 {Schwabe, Tim and Glasmachers, Tobias and Acosta,
                  Maribel},
  pages =	 {880-894},
  crossref =	 {acml22},
  abstract =	 {Recurrent Neural Networks are an integral part of
                  modern machine learning. They are good at performing
                  tasks on sequential data. However, long sequences
                  are still a problem for those models due to the
                  well-known exploding/vanishing gradient problem. In
                  this work, we build on recent approaches to
                  interpreting the gradient problem as instability of
                  the underlying dynamical system. We extend previous
                  approaches to systems with top-down feedback, which
                  is abundant in biological neural networks. We prove
                  that the resulting system is stable for arbitrary
                  depth and width and confirm this empirically. We
                  further show that its performance is on par with
                  LSTM and related approaches on standard benchmarks.}
}

@InProceedings{mahon22,
  title =	 {Efficient Deep Clustering of Human Activities and
                  How to Improve Evaluation},
  author =	 {Mahon, Louis and Lukasiewicz, Thomas},
  pages =	 {722-737},
  crossref =	 {acml22},
  abstract =	 {There has been much recent research on human
                  activity recognition (HAR), due to the proliferation
                  of wearable sensors in watches and phones, and the
                  advances of deep learning methods, which avoid the
                  need to manually extract features from raw sensor
                  signals. A significant disadvantage of deep learning
                  applied to HAR is the need for manually labelled
                  training data, which is especially difficult to
                  obtain for HAR datasets. Progress is starting to be
                  made in the unsupervised setting, in the form of
                  deep HAR clustering models, which can assign labels
                  to data without having been given any labels to
                  train on, but there are problems with evaluating
                  deep HAR clustering models, which makes assessing
                  the field and devising new methods difficult. In
                  this paper, we highlight several distinct problems
                  with how deep HAR clustering models are evaluated,
                  describing these problems in detail and conducting
                  careful experiments to explicate the effect that
                  they can have on results. Additionally, we present a
                  new deep clustering model for HAR. When tested under
                  our proposed settings, our model performs better
                  than (or on par with) existing models, while also
                  being more efficient and scalable by avoiding the
                  need for an autoencoder.}
}

@InProceedings{tang22,
  title =	 {Multi-class Classification from Multiple Unlabeled
                  Datasets with Partial Risk Regularization},
  author =	 {Tang, Yuting and Lu, Nan and Zhang, Tianyi and
                  Sugiyama, Masashi},
  pages =	 {990-1005},
  crossref =	 {acml22},
  abstract =	 {Recent years have witnessed a great success of
                  supervised deep learning, where predictive models
                  were trained from a large amount of fully labeled
                  data. However, in practice, labeling such big data
                  can be very costly and may not even be possible for
                  privacy reasons. Therefore, in this paper, we aim to
                  learn an accurate classifier without any class
                  labels. More specifically, we consider the case
                  where multiple sets of unlabeled data and only their
                  class priors, i.e., the proportions of each class,
                  are available. Under this problem setup, we first
                  derive an unbiased estimator of the classification
                  risk that can be estimated from the given unlabeled
                  sets and theoretically analyze the generalization
                  error of the learned classifier. We then find that
                  the classifier obtained as such tends to cause
                  overfitting as its empirical risks go negative
                  during training. To prevent overfitting, we further
                  propose a partial risk regularization that maintains
                  the partial risks with respect to unlabeled datasets
                  and classes to certain levels. Experiments
                  demonstrate that our method effectively mitigates
                  overfitting and outperforms state-of-the-art methods
                  for learning from multiple unlabeled sets.}
}

@InProceedings{gkolemis22,
  title =	 {DALE: Differential Accumulated Local Effects for
                  efficient and accurate global explanations},
  author =	 {Gkolemis, Vasilis and Dalamagas, Theodore and Diou,
                  Christos},
  pages =	 {375-390},
  crossref =	 {acml22},
  abstract =	 {Accumulated Local Effect (ALE) is a method for
                  accurately estimating feature effects, overcoming
                  fundamental failure modes of previously-existed
                  methods, such as Partial Dependence Plots. However,
                  \textit{ALE's approximation}, i.e.~the method for
                  estimating ALE from the limited samples of the
                  training set, faces two weaknesses. First, it does
                  not scale well in cases where the input has high
                  dimensionality, and, second, it is vulnerable to
                  out-of-distribution (OOD) sampling when the training
                  set is relatively small. In this paper, we propose a
                  novel ALE approximation, called Differential
                  Accumulated Local Effects (DALE), which can be used
                  in cases where the ML model is differentiable and an
                  auto-differentiable framework is accessible. Our
                  proposal has significant computational advantages,
                  making feature effect estimation applicable to
                  high-dimensional Machine Learning scenarios with
                  near-zero computational overhead. Furthermore, DALE
                  does not create artificial points for calculating
                  the feature effect, resolving misleading estimations
                  due to OOD sampling. Finally, we formally prove
                  that, under some hypotheses, DALE is an unbiased
                  estimator of ALE and we present a method for
                  quantifying the standard error of the
                  explanation. Experiments using both synthetic and
                  real datasets demonstrate the value of the proposed
                  approach.}
}

@InProceedings{kumar22,
  title =	 {Deep Reinforcement Learning for High-Frequency
                  Market Making},
  author =	 {Kumar, Pankaj},
  pages =	 {531-546},
  crossref =	 {acml22},
  abstract =	 {High-frequency market making is a algorithmic
                  trading strategy in which an agent provides
                  liquidity at the same time as quoting a bid price
                  and an ask price on a security. The strategy reap
                  profits in the form of the spread between the quoted
                  price placed on the buy and sell prices. Due to
                  complexity in inventory risk, counterparties to
                  trades and information asymmetry, the understanding
                  of high-frequency market making algorithms is
                  relatively unexplored by academics across
                  disciplines. In this paper, we develop realistic
                  simulations of limit order markets and use them to
                  design a high-frequency market making agent using
                  Deep Recurrent Q-Networks. Our approach outperforms
                  a prominent benchmark strategy from literature,
                  which uses temporal-difference reinforcement
                  learning to design market making agents. Using the
                  simulation framework, we analyse how the maker-take
                  fee, a feature of market design, affects market
                  quality and the agent's profitability. The agents
                  successfully reproduce stylised facts in historical
                  trade data from each simulation.}
}

@InProceedings{haruta22,
  title =	 {A Novel Graph Aggregation Method Based on Feature
                  Distribution Around Each Ego-node for Heterophily},
  author =	 {Shuichiro Haruta and Tatsuya Konishi and Mori
                  Kurokawa},
  pages =	 {452-466},
  crossref =	 {acml22},
  abstract =	 {In this paper, we propose a novel graph aggregation
                  method based on feature distribution around each
                  ego-node (a node to which features are aggregated)
                  for heterophily. In heterophily graphs, labels of
                  neighboring nodes can be uniformly distributed. In
                  such case, aggregated features by existing GNNs will
                  be always similar regardless of the label of
                  ego-node and fail to capture useful information for
                  a node classification task. Since the existing
                  methods basically ignore label distribution around
                  the ego-node, we attempt to handle heterophily
                  graphs through dynamic aggregations so that nodes
                  with similar vicinity characteristics exhibit
                  similar behavior. In particular, we adjust the
                  amount of aggregation based on the features
                  generated by higher-order neighbors, since they
                  reflect the label distribution around each
                  ego-node. By doing this, we can take the influence
                  of distant nodes into account while adapting local
                  structures of each node. Extensive experiments
                  demonstrate that the proposed method achieves higher
                  performance in heterophily graphs by up to 14.68\%
                  compared with existing methods.}
}

@InProceedings{wang22-2,
  title =	 {Evaluating the perceived safety of urban city via
                  maximum entropy deep inverse reinforcement learning},
  author =	 {Wang, Yaxuan and Zeng, Zhixin and Zhao, Qijun},
  pages =	 {1085-1100},
  crossref =	 {acml22},
  abstract =	 {Inspired by expert evaluation policy for urban
                  perception, we proposed a novel inverse
                  reinforcement learning (IRL) based framework for
                  predicting urban safety and recovering the
                  corresponding reward function. We also presented a
                  scalable state representation method to model the
                  prediction problem as a Markov decision process
                  (MDP) and use reinforcement learning (RL) to solve
                  the problem. Additionally, we built a dataset called
                  SmallCity based on the crowdsourcing method to
                  conduct the research. As far as we know, this is the
                  first time the IRL approach has been introduced to
                  the urban safety perception and planning field to
                  help experts quantitatively analyze perceptual
                  features. Our results showed that IRL has promising
                  prospects in this field. We will later open-source
                  the crowdsourcing data collection site and the model
                  proposed in this paper.}
}

@InProceedings{thopalli22,
  title =	 {Domain Alignment Meets Fully Test-Time Adaptation},
  author =	 {Thopalli,Kowshik and Turaga,Pavan and Thiagarajan,
                  Jayaraman J },
  pages =	 {1006-1021},
  crossref =	 {acml22},
  abstract =	 {A foundational requirement of a deployed ML model is
                  to generalize to data drawn from a testing
                  distribution that is different from training. A
                  popular solution to this problem is to adapt a
                  pre-trained model to novel domains using only
                  unlabeled data. In this paper, we focus on a
                  challenging variant of this problem, where access to
                  the original source data is restricted. While fully
                  test-time adaptation (FTTA) and unsupervised domain
                  adaptation (UDA) are closely related, the advances
                  in UDA are not readily applicable to TTA, since most
                  UDA methods require access to the source
                  data. Hence, we propose a new approach, CATTAn, that
                  bridges UDA and FTTA, by relaxing the need to access
                  entire source data, through a novel deep subspace
                  alignment strategy. With a minimal overhead of
                  storing the subspace basis set for the source data,
                  CATTAn enables unsupervised alignment between source
                  and target data during adaptation. Through extensive
                  experimental evaluation on multiple 2D and 3D vision
                  benchmar ks (ImageNet-C, Office-31, OfficeHome,
                  DomainNet, PointDA-10) and model architectures, we
                  demonstrate significant gains in FTTA
                  performance. Furthermore, we make a number of
                  crucial findings on the utility of the alignment
                  objective even with inherently robust models,
                  pre-trained ViT representations and under low sample
                  availability in the target domain.}
}

@InProceedings{verine22,
  title =	 {On the expressivity of bi-Lipschitz normalizing
                  flows},
  author =	 {Verine, Alexandre and Negrevergne, Benjamin and
                  Chevaleyre, Yann and Rossi, Fabrice},
  pages =	 {1054-1069},
  crossref =	 {acml22},
  abstract =	 {An invertible function is bi-Lipschitz if both the
                  function and its inverse have bounded Lipschitz
                  constants. Most state-of-the-art Normalizing Flows
                  are bi-Lipschitz by design or by training to limit
                  numerical errors (among other things). In this
                  paper, we discuss the expressivity of bi-Lipschitz
                  Normalizing Flows and identify several target
                  distributions that are difficult to approximate
                  using such models. Then, we characterize the
                  expressivity of bi-Lipschitz Normalizing Flows by
                  giving several lower bounds on the Total Variation
                  distance between these particularly unfavorable
                  distributions and their best possible
                  approximation. Finally, we show how to use the
                  bounds to adjust the training parameters, and
                  discuss potential remedies.}
}

@InProceedings{trivedi22,
  title =	 {Noise Robust Core-stable Coalitions of Hedonic
                  Games},
  author =	 {Trivedi, Prashant and Hemachandra, Nandyala},
  pages =	 {1038-1053},
  crossref =	 {acml22},
  abstract =	 {In this work, we consider the coalition formation
                  games with an additional component, `noisy
                  preferences'. Moreover, such noisy preferences are
                  available only for a sample of coalitions. We
                  propose a multiplicative noise model (equivalent to
                  an additive noise model) and obtain the prediction
                  probability, defined as the probability that the
                  estimated PAC core-stable partition of the
                  \emph{noisy} game is also PAC core-stable for the
                  \emph{unknown noise-free} game.  This prediction
                  probability depends on the probability of a
                  combinatorial construct called an `agreement
                  event'. We explicitly obtain the agreement
                  probability for $n$ agent noisy game with $l\geq 2$
                  support noise distribution. For a user-given
                  satisfaction value on this probability, we identify
                  the noise regimes for which an estimated partition
                  is noise robust; that is, it is PAC core-stable in
                  both the noisy and noise-free games. We obtain
                  similar robustness results when the estimated
                  partition is not PAC core-stable. These noise
                  regimes correspond to the level sets of the
                  agreement probability function and are non-convex
                  sets. Moreover, an important fact is that the
                  prediction probability can be high even if high
                  noise values occur with a high probability. Further,
                  for a class of top-responsive hedonic games, we
                  obtain the bounds on the extra noisy samples
                  required to get noise robustness with a user-given
                  satisfaction value.  We completely solve the noise
                  robustness problem of a $2$ agent hedonic game. In
                  particular, we obtain the prediction probability
                  function for $l=2$ and $l=3$ noise support
                  cases. For $l=2$, the prediction probability is
                  convex in noise probability, but the noise robust
                  regime is non-convex. Its minimum value, called the
                  safety value, is 0.62; so, below 0.62, the noise
                  robust regime is the entire probability
                  simplex. However, for $l \geq 3$, the prediction
                  probability is non-convex; so, the safety value is
                  the global minima of a non-convex function and is
                  computationally hard.}
}

@InProceedings{boget22,
  title =	 {Graph annotation generative adversarial networks},
  author =	 {Boget, Yoann AND Gregorova, Magda AND Kalousis,
                  Alexandros},
  pages =	 16,
  crossref =	 {acml22},
  abstract =	 {We consider the problem of modelling
                  high-dimensional distributions and generating new
                  examples of data with complex relational feature
                  structure coherent with a graph skeleton. The model
                  we propose tackles the problem of generating the
                  data features constrained by the specific graph
                  structure of each data point by splitting the task
                  into two phases. In the first it models the
                  distribution of features associated with the nodes
                  of the given graph, in the second it complements the
                  edge features conditionally on the node features. We
                  follow the strategy of implicit distribution
                  modelling via generative adversarial network (GAN)
                  combined with permutation equivariant message
                  passing architecture operating over the sets of
                  nodes and edges. This enables generating the feature
                  vectors of all the graph objects in one go (in 2
                  phases) as opposed to a much slower one-by-one
                  generations of sequential models, prevents the need
                  for expensive graph matching procedures usually
                  needed for likelihood-based generative models, and
                  uses efficiently the network capacity by being
                  insensitive to the particular node ordering in the
                  graph representation. To the best of our knowledge,
                  this is the first method that models the feature
                  distribution along the graph skeleton allowing for
                  generations of annotated graphs with user specified
                  structures. Our experiments demonstrate the ability
                  of our model to learn complex structured
                  distributions through quantitative evaluation over
                  three annotated graph datasets.}
}

@InProceedings{chaudhuri22,
  title =	 {{ProtoBandit}: Efficient Prototype Selection via
                  Multi-Armed Bandits},
  author =	 {Chaudhuri, Arghya Roy and Jawanpuria, Pratik and
                  Mishra, Bamdev},
  pages =	 {169-184},
  crossref =	 {acml22},
  year =	 2022,
  abstract =	 {In this work, we propose a multi-armed bandit based
                  framework for identifying a compact set of
                  informative data instances (i.e., the prototypes)
                  that best represents a given target
                  set. Prototypical examples of a given dataset offer
                  interpretable insights into the underlying data
                  distribution and assist in example-based reasoning,
                  thereby influencing every sphere of human decision
                  making. A key challenge is the large-scale setting,
                  in which similarity comparison between pairs of data
                  points needs to be done for almost all possible
                  pairs. We propose to overcome this limitation by
                  employing stochastic greedy search on the space of
                  prototypical examples and multi-armed bandit
                  approach for reducing the number of similarity
                  comparisons. A salient feature of the proposed
                  approach is that the total number of similarity
                  comparisons needed is independent of the size of the
                  target set. Empirically, we observe that our
                  proposed approach, ProtoBandit, reduces the total
                  number of similarity computation calls by several
                  orders of magnitudes (100-1000 times) while
                  obtaining solutions similar in quality to those from
                  existing state-of-the-art approaches.}
}

@InProceedings{buetgolfouse22-1,
  title =	 {Robust Multi-Objective Reinforcement Learning with
                  Dynamic Preferences},
  author =	 {Buet-Golfouse, Francois and Pahwa, Parth},
  pages =	 {96-111},
  crossref =	 {acml22},
  abstract =	 {This paper considers multi-objective reinforcement
                  learning (MORL) when preferences over the multiple
                  tasks are not perfectly known. Indeed, it is often
                  the case in practice that an agent is trying to
                  achieve tasks that may have competing goals but does
                  not exactly know how to trade them off. The goal of
                  MORL is thus to learn optimal policies under a set
                  of possible preferences leading to different
                  trade-offs on the Pareto frontier. Here, we propose
                  a new method by considering the dynamics of
                  preferences over tasks. While this is a more
                  realistic setup in many scenarios, more importantly,
                  it helps us devise a simple and straightforward
                  approach by considering a surrogate state space made
                  up of both states and preferences, which leads to a
                  joint exploration of states and preferences. Static
                  (and possibly unknown) preferences can also be
                  understood as a limiting case of our framework. In
                  sum, this allows us to devise both deep Q-learning
                  and actor-critic methods based on planning under a
                  preference-dependent policy and learning the
                  multi-dimensional value function under said
                  policy. Finally, the performance and effectiveness
                  of our method are demonstrated in experiments run on
                  different domains.}
}

@InProceedings{jin22,
  title =	 {Embedding Adaptation Network with Transformer for
                  Few-Shot Action Recognition},
  author =	 {Jin, Rongrong and Wang, Xiao and Wang, Guangge and
                  Lu, Yang and Hu, Hai-Miao and Wang, Hanzi},
  pages =	 {515-530},
  crossref =	 {acml22},
  abstract =	 {Few-shot action recognition aims to classify novel
                  action categories using a few training samples. Most
                  current few-shot action recognition methods via
                  episodic training strategy mainly use the same
                  normalization method to normalize feature
                  embeddings, leading to limited performance when the
                  batch size is small. And some methods learn feature
                  embeddings individually without considering the
                  whole task, neglecting important interactive
                  information between videos in the current
                  episode. To address these problems, we propose a
                  novel embedding adaptation network with Transformer
                  (EANT) for few-shot action
                  recognition. Specifically, we first propose an
                  improved self-guided instance normalization (SGIN)
                  module to adaptively learn class-specific feature
                  embeddings in an input-dependent manner. Built upon
                  the learned feature embeddings, we design a
                  Transformer-based embedding learning (TEL) module to
                  learn task-specific feature embeddings by fully
                  capturing rich information cross videos in each
                  episodic task. Furthermore, we utilize semantic
                  knowledge among all sampled training classes as
                  additional supervisory information to improve the
                  generalization ability of the network. By this
                  means, the proposed EANT can be highly effective and
                  informative for few-shot action
                  recognition. Extensive experiments conducted on
                  several challenging few-shot action recognition
                  benchmarks show that the proposed EANT outperforms
                  several state-of-the-art methods by a large margin.}
}

@InProceedings{chen22-2,
  title =	 {Noisy Riemannian Gradient Descent for Eigenvalue
                  Computation with Application to Inexact Stochastic
                  Recursive Gradient Algorithm},
  author =	 {Chen, You-Lin and Xu, Zhiqiang and Li, Ping},
  pages =	 {201-216},
  crossref =	 {acml22},
  abstract =	 {We provide a robust convergence analysis of the
                  Riemannian gradient descent algorithm for computing
                  the leading eigenvector of a real symmetric
                  matrix. Our result characterizes the convergence
                  behavior of the algorithm under the noisy updates,
                  where noises can be generated by a stochastic
                  process or could be chosen adversarially. The noisy
                  Riemannian gradient descent has a broad range of
                  applications in machine learning and statistics,
                  e.g., streaming principal component analysis or
                  privacy-preserving spectral analysis. In particular,
                  we demonstrate the usefulness of our convergence
                  bound with a new eigengap-dependent sample
                  complexity of the inexact Riemannian stochastic
                  recursive gradient algorithm, which utilizes
                  mini-batch gradients instead of full gradients in
                  outer loops. Our robust convergence paradigm
                  strictly improves the state-of-the-art sample
                  complexity in terms of the gap dependence.}
}

@InProceedings{cheng22,
  author =	 {Jian Cheng and Yang{-}Feng Hu and Yu Dai and Xue
                  Qiao and Li Yao and Jun{-}Yan Yang},
  title =	 {Nighttime Semantic Segmentation with Unsupervised
                  Learning and Cross Attention},
  series =	 {Proceedings of Machine Learning Research},
  volume =	 228,
  publisher =	 {JMLR.org},
  year =	 2022,
  abstract =	 {In recent years, semantic segmentation has shown
                  very good performance in daytime scenes. But in
                  nighttime scenes, semantic segmentation greatly
                  reduces its accuracy. Due to the lack of large-scale
                  nighttime semantic segmentation datasets, it is
                  difficult to directly train segmentation models for
                  nighttime scenes. Therefore, it becomes important to
                  adapt the daytime scene segmentation model to the
                  nighttime scene without directly using the nighttime
                  scene segmentation dataset. In this paper, we
                  propose a framework based on unsupervised learning
                  and cross attention. The proposed method fuses
                  supervised daytime scenes and unsupervised nighttime
                  scenes, the supervision information in the daytime
                  scene and the texture information specific to the
                  nighttime scene are fully utilized, and the model is
                  adapted to both the daytime scene and the nighttime
                  scene. Consistency regulation is used to make
                  segmentation model adapt to the complex and
                  changeable night scene texture and illumination. In
                  view of the coarse correspondence of static objects
                  between day and night image pairs in the Dark Zurich
                  dataset, cross attention is proposed to make the
                  model pay more attention to the parts of the night
                  scene which are similar to the daytime
                  scene. Extensive experiments on Dark Zurich and
                  Nighttime Driving datasets show that our method
                  obtains better performance in nighttime semantic
                  segmentation.}
}

@InProceedings{lu22-1,
  title =	 {AS-IntroVAE: Adversarial Similarity Distance Makes
                  Robust IntroVAE},
  author =	 {Lu Changjie and Zheng Shen and Wang Zirui and Dib
                  Omar and Gupta Gaurav},
  pages =	 {658-673},
  crossref =	 {acml22},
  abstract =	 {Recently, introspective models like IntroVAE and
                  S-IntroVAE have excelled in image generation and
                  reconstruction tasks. The principal characteristic
                  of introspective models is the adversarial learning
                  of VAE, where the encoder attempts to distinguish
                  between the real and the fake (i.e., synthesized)
                  images. However, due to the unavailability of an
                  effective metric to evaluate the difference between
                  the real and the fake images, the posterior collapse
                  and the vanishing gradient problem still exist,
                  reducing the fidelity of the synthesized images. In
                  this paper, we propose a new variation of IntroVAE
                  called Adversarial Similarity Distance Introspective
                  Variational Autoencoder (AS-IntroVAE). We
                  theoretically analyze the vanishing gradient problem
                  and construct a new Adversarial Similarity Distance
                  (AS-Distance) using the 2-Wasserstein distance and
                  the kernel trick. With weight annealing on
                  AS-Distance and KL-Divergence, the AS-IntroVAE are
                  able to generate stable and high-quality images. The
                  posterior collapse problem is addressed by making
                  per-batch attempts to transform the image so that it
                  better fits the prior distribution in the latent
                  space. Compared with the per-image approach, this
                  strategy fosters more diverse distributions in the
                  latent space, allowing our model to produce images
                  of great diversity. Comprehensive experiments on
                  benchmark datasets demonstrate the effectiveness of
                  AS-IntroVAE on image generation and reconstruction
                  tasks.}
}

@InProceedings{buetgolfouse22-2,
  Title =	 {Fairness Trade-Offs and Partial Debiasing},
  Author =	 {Buet-Golfouse, Francois and Utyagulov, Islam},
  pages =	 {112-136},
  Crossref =	 {acml22},
  Abstract =	 {Previous literature has shown that bias mitigating
                  algorithms were sometimes prone to overfitting and
                  had poor out-of-sample generalisation. This paper is
                  first and foremost concerned with establishing a
                  mathematical framework to tackle the specific issue
                  of generalisation. Throughout this work, we consider
                  fairness trade-offs and objectives mixing
                  statistical loss over the whole sample and fairness
                  penalties on categories (which could stem from
                  different values of protected attributes),
                  encompassing partial de-biasing. We do so by
                  adopting two different but complementary viewpoints:
                  first, we consider a PAC-type setup and derive
                  probabilistic upper bounds involving sample-only
                  information; second, we leverage an asymptotic
                  framework to derive a closed-form limiting
                  distribution for the difference between the
                  empirical trade-off and the true trade-off. While
                  these results provide guarantees for learning
                  fairness metrics across categories, they also point
                  out to the key (but asymmetric) role played by class
                  imbalance. To summarise, learning fairness without
                  having access to enough category-level samples is
                  hard, and a simple numerical experiment shows that
                  it can lead to spurious results.}
}

@InProceedings{maheshwara22,
  title =	 {RoLNiP: Robust Learning Using Noisy Pairwise
                  Comparisons},
  author =	 {Samartha S. Maheshwara and Naresh Manwani},
  pages =	 {706-721},
  crossref =	 {acml22},
  abstract =	 {This paper presents a robust approach for learning
                  from noisy pairwise comparisons. We propose
                  sufficient conditions on the loss function under
                  which the risk minimization frame- work becomes
                  robust to noise in the pairwise similar dissimilar
                  data. Our approach does not require the knowledge of
                  noise rate in the uniform noise case. In the case of
                  conditional noise, the proposed method depends on
                  the noise rates. For such cases, we offer a provably
                  correct approach for estimating the noise
                  rates. Thus, we propose an end-to-end approach to
                  learning robust classifiers in this setting. We
                  experimentally show that the proposed approach
                  RoLNiP outperforms the robust state-of-the-art
                  methods for learning with noisy pairwise
                  comparisons.}
}

@InProceedings{ma22-2,
  title =	 {Asynchronous Personalized Federated Learning with
                  Irregular Clients},
  author =	 {Ma, Zichen and Lu, Yu and Li, Wenye and Cui,
                  Shuguang},
  pages =	 {706-721},
  crossref =	 {acml22},
  abstract =	 {To provide intelligent and personalized models for
                  clients, personalized federated learning (PFL)
                  enables learning from data, identifying patterns,
                  and making automated decisions in a
                  privacy-preserving manner. PFL involves independent
                  training for multiple clients with synchronous
                  aggregation steps. However, the assumptions made by
                  existing works are not realistic given the
                  heterogeneity of clients. In particular, the volume
                  and distribution of collected data vary in the
                  training process, and the clients also vary in their
                  available system configurations, which leads to vast
                  heterogeneity in the system. To address these
                  challenges, we present an \textit{asynchronous}
                  method (AsyPFL), where clients learn personalized
                  models w.r.t. local data by making the most
                  informative parameters less volatile. The central
                  server aggregates model parameters
                  asynchronously. In addition, we also reformulate PFL
                  by unifying both synchronous and asynchronous
                  updating schemes with an asynchrony-related
                  parameter. Theoretically, we show that AsyPFL’s
                  convergence rate is state-of-the-art and provide
                  guarantees of choosing key hyperparameters
                  optimally. With these theoretical guarantees, we
                  validate AsyPFL on different tasks with non-IID and
                  staleness settings. The results indicate that, given
                  a large proportion of irregular clients, AsyPFL
                  excels at empirical performance compared with
                  vanilla PFL algorithms on non-IID and IID cases.}
}
